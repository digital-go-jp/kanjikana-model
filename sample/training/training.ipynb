{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIモデル訓練サンプル\n",
    "PythonでEng-Fraサンプルデータを用いて，EnglishからFrenchへ翻訳するモデルを訓練する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プログラム説明\n",
    "\n",
    "model.py\n",
    "\n",
    "内部で，pytorchのtransformerライブラリを呼び出している。各パラメタの詳細は [Pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) を参照のこと。\n",
    "\n",
    "- emb_size    \n",
    "  単語のエンベッドサイズ\n",
    "- nhead    \n",
    "  transformerのMultiHeadAttentionのヘッド数\n",
    "- ffn_hid_dim       \n",
    "  FeedForwardNeuralNetworkの次元数\n",
    "- batch_size     \n",
    "  ミニバッチサイズ。メモリが足りないときや計算速度を早めたいときにはこのサイズを変更する\n",
    "- num_encoder_layers    \n",
    "  エンコーダ内のサブエンコーダ層の数 \n",
    "- num_decoder_layers    \n",
    "  デコーダ内のサブデコーダ層の数\n",
    "- lr   \n",
    "  学習率\n",
    "- dropout    \n",
    "  ドロップアウトの割合，1=100%\n",
    "- num_epochs    \n",
    "  学習用データを何周学習するか\n",
    "- device    \n",
    "  cuda: Cudaが使えるマシンではこれを選択\n",
    "  mps: Apple Silicornが使えるマシンではこれを選択\n",
    "  cpu: CPUで計算\n",
    "- earlystop_patient    \n",
    "  num_epochs以下でも，開発用データで，Lossが下がらなくなった回数がearlystop_patientより大きくなると，計算を終了させる\n",
    "- output_dir    \n",
    "  学習したモデルを格納するディレクトリ。ディレクトリには checkpoint_xxx.pt（xxxはepoch数）とcheckpoint_best.ptが作成され，valid lossが最も小さくなったepoch回のモデルをcheckpoint_best.ptとして保存する\n",
    "- tensorboard_logdir    \n",
    "  tensorboard のログを格納するディレクトリ。学習結果などを視覚化して表示できる。 tensorboard --logdir tensorboard_logdir で起動し，http://localhost:6006でアクセスすると表示される\n",
    "- prefix    \n",
    "  jsonl形式の訓練データ及び開発データのprefix\n",
    "- source_lang    \n",
    "  jsonl形式の訓練データ及び開発データでの，翻訳元となるデータにつけるキー\n",
    "- target_lang     \n",
    "  jsonl形式の訓練データ及び開発データでの，翻訳先となるデータにつけるキー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/utsubo-\n",
      "[nltk_data]     katsuhiko/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/utsubo-\n",
      "[nltk_data]     katsuhiko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "num_epochs:100\n",
      "Epoch: 1, Train loss: 7.208, Val loss: 6.330, Epoch time = 424.666s\n",
      "Epoch: 2, Train loss: 6.232, Val loss: 6.217, Epoch time = 417.980s\n",
      "Epoch: 3, Train loss: 6.091, Val loss: 6.581, Epoch time = 402.561s\n",
      "Epoch: 4, Train loss: 5.788, Val loss: 6.569, Epoch time = 396.619s\n",
      "Epoch: 5, Train loss: 5.462, Val loss: 5.524, Epoch time = 406.173s\n",
      "Epoch: 6, Train loss: 5.295, Val loss: 5.366, Epoch time = 413.644s\n",
      "Epoch: 7, Train loss: 5.149, Val loss: 5.130, Epoch time = 410.832s\n",
      "Epoch: 8, Train loss: 5.018, Val loss: 4.979, Epoch time = 405.375s\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/sample/training/./model.py\", line 530, in <module>\n",
      "    main()\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/sample/training/./model.py\", line 526, in main\n",
      "    KanjiKanaTransformer(args).train()\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/sample/training/./model.py\", line 473, in train\n",
      "    val_loss = self.evaluate(transformer, loss_fn)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/sample/training/./model.py\", line 302, in evaluate\n",
      "    logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/sample/training/./model.py\", line 155, in forward\n",
      "    outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 278, in forward\n",
      "    output = self.decoder(\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 602, in forward\n",
      "    output = mod(\n",
      "             ^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 1087, in forward\n",
      "    x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 1107, in _sa_block\n",
      "    x = self.self_attn(\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py\", line 1368, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/torch/nn/functional.py\", line 6285, in multi_head_attention_forward\n",
      "    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Pythonで訓練をする\n",
    "# deviceはcuda or cpu or mps\n",
    "#  mps: apple silicon\n",
    "# out of memoryが発生した際には、batch_sizeを減らす\n",
    "\n",
    "\n",
    "# 途中から計算するときには，modelディレクトリに checkpoint_xxx.pt(xxxは計算済みのepoch数)とcheckpoint_best.pt が存在すること\n",
    "\n",
    "!python ./model.py \\\n",
    "  --emb_size 512 \\\n",
    "  --nhead 8 \\\n",
    "  --ffn_hid_dim 1024 \\\n",
    "  --batch_size 64 \\\n",
    "  --num_encoder_layers 8 \\\n",
    "  --num_decoder_layers 8 \\\n",
    "  --lr 0.00002 \\\n",
    "  --dropout 0.3 \\\n",
    "  --num_epochs 100 \\\n",
    "  --device mps \\\n",
    "  --earlystop_patient 3 \\\n",
    "  --output_dir model \\\n",
    "  --tensorboard_logdir logs \\\n",
    "  --prefix translation \\\n",
    "  --source_lang eng \\\n",
    "  --target_lang fra \\\n",
    "  --train_file ../dataset/train.jsonl \\\n",
    "  --valid_file ../dataset/val.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# javaのDJLで使えるようにモデルファイルを変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python convert.py  \\\n",
    "    --model_file=model/checkpoint_best.pt \\\n",
    "    --model_script=model/script.pt \\\n",
    "    --encoder=model/encoder.pt \\\n",
    "    --decoder=model/decoder.pt \\\n",
    "    --positional_encoding=model/positional_encoding.pt \\\n",
    "    --generator=model/generator.pt \\\n",
    "    --src_tok_emb=model/src_tok_emb.pt \\\n",
    "    --tgt_tok_emb=model/tgt_tok_emb.pt \\\n",
    "    --vocab_src=model/vocab_src.txt \\\n",
    "    --vocab_tgt=model/vocab_tgt.txt \\\n",
    "    --params=model/params.json \\\n",
    "    --device=cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
