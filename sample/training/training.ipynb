{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonで訓練をする\n",
    "# deviceはcuda or cpu or mps\n",
    "#  mps: apple silicon\n",
    "# out of memoryが発生した際には、batch_sizeを減らす\n",
    "\n",
    "\n",
    "# 途中から計算するときには，modelディレクトリに checkpoint_xxx.pt(xxxは計算済みのepoch数)とcheckpoint_best.pt が存在すること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "model.py\n",
    "\n",
    "- emb_size    \n",
    "  単語のエンベッドサイズ\n",
    "- nhead\n",
    "  transformerのMultiHeadAttentionのヘッド数\n",
    "- ffn_hid_dim    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs:100\n",
      "Epoch: 1, Train loss: 2.971, Val loss: 2.371, Epoch time = 790.949s\n",
      "Epoch: 2, Train loss: 2.369, Val loss: 2.166, Epoch time = 788.740s\n",
      "Epoch: 3, Train loss: 2.227, Val loss: 2.084, Epoch time = 789.483s\n",
      "Epoch: 4, Train loss: 2.144, Val loss: 2.010, Epoch time = 788.312s\n",
      "Epoch: 5, Train loss: 2.081, Val loss: 1.942, Epoch time = 788.076s\n",
      "Epoch: 6, Train loss: 2.026, Val loss: 1.883, Epoch time = 789.471s\n",
      "Epoch: 7, Train loss: 1.978, Val loss: 1.832, Epoch time = 788.610s\n",
      "Epoch: 8, Train loss: 1.935, Val loss: 1.792, Epoch time = 788.455s\n",
      "Epoch: 9, Train loss: 1.896, Val loss: 1.742, Epoch time = 789.635s\n",
      "Epoch: 10, Train loss: 1.861, Val loss: 1.704, Epoch time = 788.345s\n",
      "Epoch: 11, Train loss: 1.828, Val loss: 1.671, Epoch time = 789.236s\n",
      "Epoch: 12, Train loss: 1.797, Val loss: 1.637, Epoch time = 788.691s\n",
      "Epoch: 13, Train loss: 1.768, Val loss: 1.603, Epoch time = 788.918s\n",
      "Epoch: 14, Train loss: 1.741, Val loss: 1.573, Epoch time = 787.437s\n",
      "Epoch: 15, Train loss: 1.715, Val loss: 1.546, Epoch time = 788.975s\n",
      "Epoch: 16, Train loss: 1.691, Val loss: 1.528, Epoch time = 786.953s\n",
      "Epoch: 17, Train loss: 1.668, Val loss: 1.499, Epoch time = 788.407s\n",
      "Epoch: 18, Train loss: 1.646, Val loss: 1.476, Epoch time = 786.736s\n",
      "Epoch: 19, Train loss: 1.626, Val loss: 1.457, Epoch time = 787.660s\n",
      "Epoch: 20, Train loss: 1.606, Val loss: 1.439, Epoch time = 790.309s\n",
      "Epoch: 21, Train loss: 1.588, Val loss: 1.417, Epoch time = 787.171s\n",
      "Epoch: 22, Train loss: 1.570, Val loss: 1.401, Epoch time = 789.115s\n",
      "Epoch: 23, Train loss: 1.553, Val loss: 1.386, Epoch time = 786.267s\n",
      "Epoch: 24, Train loss: 1.536, Val loss: 1.368, Epoch time = 787.138s\n",
      "Epoch: 25, Train loss: 1.521, Val loss: 1.357, Epoch time = 788.444s\n",
      "Epoch: 26, Train loss: 1.505, Val loss: 1.337, Epoch time = 785.954s\n",
      "Epoch: 27, Train loss: 1.491, Val loss: 1.325, Epoch time = 787.506s\n",
      "Epoch: 28, Train loss: 1.477, Val loss: 1.309, Epoch time = 786.190s\n",
      "Epoch: 29, Train loss: 1.463, Val loss: 1.300, Epoch time = 787.692s\n",
      "Epoch: 30, Train loss: 1.450, Val loss: 1.286, Epoch time = 788.146s\n",
      "Epoch: 31, Train loss: 1.438, Val loss: 1.273, Epoch time = 788.297s\n",
      "Epoch: 32, Train loss: 1.425, Val loss: 1.264, Epoch time = 787.426s\n",
      "Epoch: 33, Train loss: 1.414, Val loss: 1.251, Epoch time = 788.240s\n",
      "Epoch: 34, Train loss: 1.402, Val loss: 1.240, Epoch time = 788.518s\n",
      "Epoch: 35, Train loss: 1.391, Val loss: 1.229, Epoch time = 787.798s\n",
      "Epoch: 36, Train loss: 1.380, Val loss: 1.222, Epoch time = 787.418s\n",
      "Epoch: 37, Train loss: 1.370, Val loss: 1.211, Epoch time = 784.838s\n",
      "Epoch: 38, Train loss: 1.360, Val loss: 1.199, Epoch time = 786.923s\n",
      "Epoch: 39, Train loss: 1.350, Val loss: 1.189, Epoch time = 785.953s\n",
      "Epoch: 40, Train loss: 1.340, Val loss: 1.182, Epoch time = 788.439s\n",
      "Epoch: 41, Train loss: 1.332, Val loss: 1.169, Epoch time = 787.965s\n",
      "Epoch: 42, Train loss: 1.323, Val loss: 1.162, Epoch time = 787.058s\n",
      "Epoch: 43, Train loss: 1.313, Val loss: 1.157, Epoch time = 785.430s\n",
      "Epoch: 44, Train loss: 1.305, Val loss: 1.144, Epoch time = 787.203s\n",
      "Epoch: 45, Train loss: 1.297, Val loss: 1.138, Epoch time = 787.161s\n",
      "Epoch: 46, Train loss: 1.288, Val loss: 1.132, Epoch time = 788.180s\n",
      "Epoch: 47, Train loss: 1.281, Val loss: 1.126, Epoch time = 787.970s\n",
      "Epoch: 48, Train loss: 1.273, Val loss: 1.121, Epoch time = 787.759s\n",
      "Epoch: 49, Train loss: 1.265, Val loss: 1.115, Epoch time = 789.343s\n",
      "Epoch: 50, Train loss: 1.259, Val loss: 1.105, Epoch time = 785.598s\n",
      "Epoch: 51, Train loss: 1.251, Val loss: 1.098, Epoch time = 785.701s\n",
      "Epoch: 52, Train loss: 1.244, Val loss: 1.091, Epoch time = 785.965s\n",
      "Epoch: 53, Train loss: 1.237, Val loss: 1.083, Epoch time = 788.267s\n",
      "Epoch: 54, Train loss: 1.230, Val loss: 1.077, Epoch time = 785.105s\n",
      "Epoch: 55, Train loss: 1.223, Val loss: 1.072, Epoch time = 787.982s\n",
      "Epoch: 56, Train loss: 1.217, Val loss: 1.063, Epoch time = 786.621s\n",
      "Epoch: 57, Train loss: 1.211, Val loss: 1.059, Epoch time = 787.006s\n",
      "Epoch: 58, Train loss: 1.204, Val loss: 1.049, Epoch time = 787.993s\n",
      "Epoch: 59, Train loss: 1.199, Val loss: 1.049, Epoch time = 789.065s\n",
      "Epoch: 60, Train loss: 1.191, Val loss: 1.040, Epoch time = 787.279s\n",
      "Epoch: 61, Train loss: 1.186, Val loss: 1.035, Epoch time = 786.954s\n",
      "Epoch: 62, Train loss: 1.181, Val loss: 1.030, Epoch time = 787.899s\n",
      "Epoch: 63, Train loss: 1.174, Val loss: 1.028, Epoch time = 788.108s\n",
      "Epoch: 64, Train loss: 1.169, Val loss: 1.022, Epoch time = 786.725s\n",
      "Epoch: 65, Train loss: 1.164, Val loss: 1.015, Epoch time = 787.710s\n"
     ]
    }
   ],
   "source": [
    "!python ./model.py \\\n",
    "  --emb_size 512 \\\n",
    "  --nhead 8 \\\n",
    "  --ffn_hid_dim 1024 \\\n",
    "  --batch_size 32 \\\n",
    "  --num_encoder_layers 8 \\\n",
    "  --num_decoder_layers 8 \\\n",
    "  --lr 0.00002 \\\n",
    "  --dropout 0.3 \\\n",
    "  --num_epochs 100 \\\n",
    "  --device cuda \\\n",
    "  --earlystop_patient 3 \\\n",
    "  --output_dir model \\\n",
    "  --tensorboard_logdir logs \\\n",
    "  --prefix translation \\\n",
    "  --source_lang eng \\\n",
    "  --target_lang fra \\\n",
    "  --train_file ../dataset/train.jsonl \\\n",
    "  --valid_file ../dataset/val.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# javaのDJLで使えるようにモデルファイルを変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python convert.py  \\\n",
    "    --model_file=model/checkpoint_best.pt \\\n",
    "    --model_script=model/script.pt \\\n",
    "    --encoder=model/encoder.pt \\\n",
    "    --decoder=model/decoder.pt \\\n",
    "    --positional_encoding=model/positional_encoding.pt \\\n",
    "    --generator=model/generator.pt \\\n",
    "    --src_tok_emb=model/src_tok_emb.pt \\\n",
    "    --tgt_tok_emb=model/tgt_tok_emb.pt \\\n",
    "    --vocab_src=model/vocab_src.txt \\\n",
    "    --vocab_tgt=model/vocab_tgt.txt \\\n",
    "    --params=model/params.json \\\n",
    "    --device=cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
