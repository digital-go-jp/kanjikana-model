{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pythonで推論を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def n_gram_generator(sentence,n= 2,n_gram= False):\n",
    "    '''\n",
    "    N-Gram generator with parameters sentence\n",
    "    n is for number of n_grams\n",
    "    The n_gram parameter removes repeating n_grams \n",
    "    '''\n",
    "    sentence = sentence.lower() # converting to lower case\n",
    "    sent_arr = np.array(sentence.split()) # split to string arrays\n",
    "    length = len(sent_arr)\n",
    "\n",
    "    word_list = []\n",
    "    for i in range(length+1):\n",
    "        if i < n:\n",
    "            continue\n",
    "        word_range = list(range(i-n,i))\n",
    "        s_list = sent_arr[word_range]\n",
    "        string = ' '.join(s_list) # converting list to strings\n",
    "        word_list.append(string) # append to word_list\n",
    "        if n_gram:\n",
    "            word_list = list(set(word_list))\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# https://stackoverflow.com/questions/56968434/bleu-score-in-python-from-scratch\n",
    "def bleu_score(original,machine_translated):\n",
    "    '''\n",
    "    Bleu score function given a orginal and a machine translated sentences\n",
    "    '''\n",
    "    mt_length = len(machine_translated.split())\n",
    "    o_length = len(original.split())\n",
    "\n",
    "    # Brevity Penalty \n",
    "    if mt_length>o_length:\n",
    "        BP=1\n",
    "    else:\n",
    "        penality=1-(mt_length/o_length)\n",
    "        BP=np.exp(penality)\n",
    "\n",
    "    # Clipped precision\n",
    "    clipped_precision_score = []\n",
    "    for i in range(1, 5):\n",
    "        original_n_gram = Counter(n_gram_generator(original,i))\n",
    "        machine_n_gram = Counter(n_gram_generator(machine_translated,i))\n",
    "\n",
    "        c = sum(machine_n_gram.values())\n",
    "        for j in machine_n_gram:\n",
    "            if j in original_n_gram:\n",
    "                if machine_n_gram[j] > original_n_gram[j]:\n",
    "                    machine_n_gram[j] = original_n_gram[j]\n",
    "            else:\n",
    "                machine_n_gram[j] = 0\n",
    "\n",
    "        #print (sum(machine_n_gram.values()), c)\n",
    "        clipped_precision_score.append(sum(machine_n_gram.values())/c)\n",
    "\n",
    "    #print (clipped_precision_score)\n",
    "\n",
    "    weights =[0.25]*4\n",
    "\n",
    "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
    "    s = BP * math.exp(math.fsum(s))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27098211583470044\n"
     ]
    }
   ],
   "source": [
    "original = \"It is a guide to action which ensures that the military alwasy obeys the command of the party\"\n",
    "machine_translated = \"It is the guiding principle which guarantees the military forces alwasy being under the command of the party\"\n",
    "\n",
    "print (bleu_score(original, machine_translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/bettkipkemoi/Bleu-Score/blob/main/Bleu.ipynb\n",
    "\n",
    "from math import sqrt, log, exp\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the n-grams from the given text\n",
    "def get_ngrams(text, order):\n",
    "    \"\"\"\n",
    "    Given a string `text` and an integer `order`, returns a Counter object containing\n",
    "    the frequency counts of all ngrams of size `order` in the string.\n",
    "    \"\"\"\n",
    "    ngrams = Counter()\n",
    "\n",
    "    words = text.split()\n",
    "    for i in range(len(words)- order+1):\n",
    "      ngram = \" \". join(words[i: i + order])\n",
    "      ngrams[ngram] += 1\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(hypothesis, references):\n",
    "    \n",
    "    bleu=0\n",
    "    p1=0\n",
    "    p2=0\n",
    "    p3=0\n",
    "    p4=0\n",
    "    bp=1\n",
    "    \n",
    "\n",
    "    # 1. Find the closest reference to the hypothesis\n",
    "    closest_size=100000\n",
    "    closest_ref=[]\n",
    "\n",
    "    for ref in references:\n",
    "      ref_size = len(ref)\n",
    "      if abs(len(hypothesis) - ref_size) < closest_size:\n",
    "        closest_size = abs(len(hypothesis) - ref_size)\n",
    "        closest_ref = ref\n",
    "        pass\n",
    "\n",
    "    # 2. Calculating pn\n",
    "    pns=[]\n",
    "    for order in range(1,5):\n",
    "      # calculate intersection and union of n-grams\n",
    "      # hint: use the get_ngrams function you implemented\n",
    "      # calculate pn for each order\n",
    "        hyp_ngrams = get_ngrams(hypothesis, order)\n",
    "        hyp_count = Counter(hyp_ngrams)\n",
    "        closest_ref_ngrams = get_ngrams(closest_ref, order)\n",
    "        closest_ref_count = Counter(closest_ref_ngrams)\n",
    "        intersection_count = dict(hyp_count & closest_ref_count)\n",
    "        intersection_size = sum(intersection_count.values())\n",
    "        hyp_size = max(len(hyp_ngrams), 1)\n",
    "        p_n = intersection_size / hyp_size\n",
    "        pns.append(p_n)\n",
    "        pass\n",
    "\n",
    "    # 3. Calculating the brevity penalty\n",
    "    bp=1\n",
    "    c=len(hypothesis)\n",
    "    r=min(abs(len(ref) - c) for ref in references)\n",
    "    if c > r:\n",
    "      bp = 1.0\n",
    "    else:\n",
    "      bp = exp(1 - r / c)\n",
    "\n",
    "    # 4. Calculating the BLEU score\n",
    "    weights = [0.25] * 4\n",
    "    bleu=bp * exp(sum(w * log(p_n) for w, p_n in zip(weights, pns)))    \n",
    "    \n",
    "    # Assigning values to p1, p2, p3, p4!\n",
    "    p1, p2, p3, p4 = pns\n",
    "\n",
    "    \n",
    "    # Do not change the variable name\n",
    "    return bleu, p1, p2, p3, p4, bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis=\"Abandon all hope , ye who enter here\"\n",
    "references=[\"All hope abandon , ye who enter here\", \"All hope abandon , ye who enter in !\", \"Leave every hope, ye that enter\", \"Leave all hope , ye that enter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.541\n"
     ]
    }
   ],
   "source": [
    "bleu, p1, p2, p3, p4, bp=calculate_bleu(hypothesis, references)\n",
    "print(\"BLEU: %.3f\" % bleu) # sanity check: 0.5 < BLEU < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"It is a guide to action which ensures that the military alwasy obeys the command of the party\"\n",
    "machine_translated = \"It is the guiding principle which guarantees the military forces alwasy being under the command of the party\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.279\n"
     ]
    }
   ],
   "source": [
    "bleu, p1, p2, p3, p4, bp=calculate_bleu(original, [machine_translated])\n",
    "print(\"BLEU: %.3f\" % bleu) # sanity check: 0.5 < BLEU < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/sample/inference_py/generate.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  last_checkpoint = torch.load(self.args.model_file, map_location=torch.device(self.args.device))\n",
      "/home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/analysis01/src/kanjikana-model/sample/inference_py/generate.py\", line 185, in <module>\n",
      "    main()\n",
      "  File \"/home/analysis01/src/kanjikana-model/sample/inference_py/generate.py\", line 181, in main\n",
      "    KanjiKanaTransformerTest(args).generate()\n",
      "  File \"/home/analysis01/src/kanjikana-model/sample/inference_py/generate.py\", line 159, in generate\n",
      "    predict_sentence= \" \".join(self.vocab_transform[self.args.target_lang].lookup_tokens(list(tgt_token.cpu().numpy()))).replace(SPECIAL_SYMBOLS[BOS_IDX], \"\").replace(SPECIAL_SYMBOLS[EOS_IDX], \"\").replace(\" \",\"\")\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Vocab' object has no attribute 'lookup_tokens'\n"
     ]
    }
   ],
   "source": [
    "!python generate.py --test_file='../dataset/test.jsonl' --model_file='../training/model/checkpoint_best.pt' --outfile=\"out.txt\" --device=\"cpu\" --nbest=5 --beam_width=5 --max_len=100  --search='beam'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
