{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pythonで推論を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def n_gram_generator(sentence,n= 2,n_gram= False):\n",
    "    '''\n",
    "    N-Gram generator with parameters sentence\n",
    "    n is for number of n_grams\n",
    "    The n_gram parameter removes repeating n_grams \n",
    "    '''\n",
    "    sentence = sentence.lower() # converting to lower case\n",
    "    sent_arr = np.array(sentence.split()) # split to string arrays\n",
    "    length = len(sent_arr)\n",
    "\n",
    "    word_list = []\n",
    "    for i in range(length+1):\n",
    "        if i < n:\n",
    "            continue\n",
    "        word_range = list(range(i-n,i))\n",
    "        s_list = sent_arr[word_range]\n",
    "        string = ' '.join(s_list) # converting list to strings\n",
    "        word_list.append(string) # append to word_list\n",
    "        if n_gram:\n",
    "            word_list = list(set(word_list))\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# https://stackoverflow.com/questions/56968434/bleu-score-in-python-from-scratch\n",
    "def bleu_score(original,machine_translated):\n",
    "    '''\n",
    "    Bleu score function given a orginal and a machine translated sentences\n",
    "    '''\n",
    "    mt_length = len(machine_translated.split())\n",
    "    o_length = len(original.split())\n",
    "\n",
    "    # Brevity Penalty \n",
    "    if mt_length>o_length:\n",
    "        BP=1\n",
    "    else:\n",
    "        penality=1-(mt_length/o_length)\n",
    "        BP=np.exp(penality)\n",
    "\n",
    "    # Clipped precision\n",
    "    clipped_precision_score = []\n",
    "    for i in range(1, 5):\n",
    "        original_n_gram = Counter(n_gram_generator(original,i))\n",
    "        machine_n_gram = Counter(n_gram_generator(machine_translated,i))\n",
    "\n",
    "        c = sum(machine_n_gram.values())\n",
    "        for j in machine_n_gram:\n",
    "            if j in original_n_gram:\n",
    "                if machine_n_gram[j] > original_n_gram[j]:\n",
    "                    machine_n_gram[j] = original_n_gram[j]\n",
    "            else:\n",
    "                machine_n_gram[j] = 0\n",
    "\n",
    "        #print (sum(machine_n_gram.values()), c)\n",
    "        clipped_precision_score.append(sum(machine_n_gram.values())/c)\n",
    "\n",
    "    #print (clipped_precision_score)\n",
    "\n",
    "    weights =[0.25]*4\n",
    "\n",
    "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
    "    s = BP * math.exp(math.fsum(s))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27098211583470044\n"
     ]
    }
   ],
   "source": [
    "original = \"It is a guide to action which ensures that the military alwasy obeys the command of the party\"\n",
    "machine_translated = \"It is the guiding principle which guarantees the military forces alwasy being under the command of the party\"\n",
    "\n",
    "print (bleu_score(original, machine_translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/bettkipkemoi/Bleu-Score/blob/main/Bleu.ipynb\n",
    "\n",
    "from math import sqrt, log, exp\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the n-grams from the given text\n",
    "def get_ngrams(text, order):\n",
    "    \"\"\"\n",
    "    Given a string `text` and an integer `order`, returns a Counter object containing\n",
    "    the frequency counts of all ngrams of size `order` in the string.\n",
    "    \"\"\"\n",
    "    ngrams = Counter()\n",
    "\n",
    "    words = text.split()\n",
    "    for i in range(len(words)- order+1):\n",
    "      ngram = \" \". join(words[i: i + order])\n",
    "      ngrams[ngram] += 1\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(hypothesis, references):\n",
    "    \n",
    "    bleu=0\n",
    "    p1=0\n",
    "    p2=0\n",
    "    p3=0\n",
    "    p4=0\n",
    "    bp=1\n",
    "    \n",
    "\n",
    "    # 1. Find the closest reference to the hypothesis\n",
    "    closest_size=100000\n",
    "    closest_ref=[]\n",
    "\n",
    "    for ref in references:\n",
    "      ref_size = len(ref)\n",
    "      if abs(len(hypothesis) - ref_size) < closest_size:\n",
    "        closest_size = abs(len(hypothesis) - ref_size)\n",
    "        closest_ref = ref\n",
    "        pass\n",
    "\n",
    "    # 2. Calculating pn\n",
    "    pns=[]\n",
    "    for order in range(1,5):\n",
    "      # calculate intersection and union of n-grams\n",
    "      # hint: use the get_ngrams function you implemented\n",
    "      # calculate pn for each order\n",
    "        hyp_ngrams = get_ngrams(hypothesis, order)\n",
    "        hyp_count = Counter(hyp_ngrams)\n",
    "        closest_ref_ngrams = get_ngrams(closest_ref, order)\n",
    "        closest_ref_count = Counter(closest_ref_ngrams)\n",
    "        intersection_count = dict(hyp_count & closest_ref_count)\n",
    "        intersection_size = sum(intersection_count.values())\n",
    "        hyp_size = max(len(hyp_ngrams), 1)\n",
    "        p_n = intersection_size / hyp_size\n",
    "        pns.append(p_n)\n",
    "        pass\n",
    "\n",
    "    # 3. Calculating the brevity penalty\n",
    "    bp=1\n",
    "    c=len(hypothesis)\n",
    "    r=min(abs(len(ref) - c) for ref in references)\n",
    "    if c > r:\n",
    "      bp = 1.0\n",
    "    else:\n",
    "      bp = exp(1 - r / c)\n",
    "\n",
    "    # 4. Calculating the BLEU score\n",
    "    weights = [0.25] * 4\n",
    "    bleu=bp * exp(sum(w * log(p_n) for w, p_n in zip(weights, pns)))    \n",
    "    \n",
    "    # Assigning values to p1, p2, p3, p4!\n",
    "    p1, p2, p3, p4 = pns\n",
    "\n",
    "    \n",
    "    # Do not change the variable name\n",
    "    return bleu, p1, p2, p3, p4, bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis=\"Abandon all hope , ye who enter here\"\n",
    "references=[\"All hope abandon , ye who enter here\", \"All hope abandon , ye who enter in !\", \"Leave every hope, ye that enter\", \"Leave all hope , ye that enter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.541\n"
     ]
    }
   ],
   "source": [
    "bleu, p1, p2, p3, p4, bp=calculate_bleu(hypothesis, references)\n",
    "print(\"BLEU: %.3f\" % bleu) # sanity check: 0.5 < BLEU < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"It is a guide to action which ensures that the military alwasy obeys the command of the party\"\n",
    "machine_translated = \"It is the guiding principle which guarantees the military forces alwasy being under the command of the party\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.279\n"
     ]
    }
   ],
   "source": [
    "bleu, p1, p2, p3, p4, bp=calculate_bleu(original, [machine_translated])\n",
    "print(\"BLEU: %.3f\" % bleu) # sanity check: 0.5 < BLEU < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論\n",
    "Greedyサーチで推論する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate.py --test_file='../dataset/test.jsonl' --model_file='../training/model/checkpoint_best.pt' --outfile=\"outfile.txt\" --device=\"cpu\" --max_len=100  --search='greedy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価\n",
    "BlueScoreでGreedyサーチで推論した翻訳結果と，実際の翻訳との比較を行い，評価する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://thepythoncode.com/article/bleu-score-in-python\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
