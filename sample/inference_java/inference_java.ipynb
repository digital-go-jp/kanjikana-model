{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Javaで推論を実行する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンパイルする\n",
    "mavenでコンパイルする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;34mINFO\u001b[m] Scanning for projects...\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m----------------< \u001b[0;36mjp.go.digital.kanjikana:java_sample\u001b[0;1m >-----------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1mBuilding java_sample 1.0\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--------------------------------[ jar ]---------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-clean-plugin:2.5:clean\u001b[m \u001b[1m(default-clean)\u001b[m @ \u001b[36mjava_sample\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Deleting /home/analysis01/src/kanjikana-model/sample/inference_java/target\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-antrun-plugin:1.3:run\u001b[m \u001b[1m(default-cli)\u001b[m @ \u001b[36mjava_sample\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Executing tasks\n",
      "[\u001b[1;34mINFO\u001b[m] Executed tasks\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1;32mBUILD SUCCESS\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Total time: 1.074 s\n",
      "[\u001b[1;34mINFO\u001b[m] Finished at: 2025-01-23T09:36:31+09:00\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!mvn clean antrun:run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;34mINFO\u001b[m] Scanning for projects...\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m----------------< \u001b[0;36mjp.go.digital.kanjikana:java_sample\u001b[0;1m >-----------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1mBuilding java_sample 1.0\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--------------------------------[ jar ]---------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-resources-plugin:3.2.0:resources\u001b[m \u001b[1m(default-resources)\u001b[m @ \u001b[36mjava_sample\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Using 'UTF-8' encoding to copy filtered resources.\n",
      "[\u001b[1;34mINFO\u001b[m] Using 'UTF-8' encoding to copy filtered properties files.\n",
      "[\u001b[1;34mINFO\u001b[m] Copying 0 resource\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-compiler-plugin:3.1:compile\u001b[m \u001b[1m(default-compile)\u001b[m @ \u001b[36mjava_sample\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Changes detected - recompiling the module!\n",
      "[\u001b[1;34mINFO\u001b[m] Compiling 10 source files to /home/analysis01/src/kanjikana-model/sample/inference_java/target/classes\n",
      "[\u001b[1;33mWARNING\u001b[m] /home/analysis01/src/kanjikana-model/sample/inference_java/src/main/java/jp/go/digital/sample/Parameters.java: /home/analysis01/src/kanjikana-model/sample/inference_java/src/main/java/jp/go/digital/sample/Parameters.javaは推奨されないAPIを使用またはオーバーライドしています。\n",
      "[\u001b[1;33mWARNING\u001b[m] /home/analysis01/src/kanjikana-model/sample/inference_java/src/main/java/jp/go/digital/sample/Parameters.java: 詳細は、-Xlint:deprecationオプションを指定して再コンパイルしてください。\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-assembly-plugin:3.5.0:single\u001b[m \u001b[1m(default-cli)\u001b[m @ \u001b[36mjava_sample\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Building jar: /home/analysis01/src/kanjikana-model/sample/inference_java/target/java_sample-1.0-jar-with-dependencies.jar\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1;32mBUILD SUCCESS\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Total time: 9.330 s\n",
      "[\u001b[1;34mINFO\u001b[m] Finished at: 2025-01-23T09:36:41+09:00\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!mvn compile assembly:single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証データを用いて実行する\n",
    "Greedyサーチで検証用データを用いて、推論をおこなう\n",
    "\n",
    "オプションの項目は次の通り\n",
    "\n",
    "### VMオプション\n",
    "\n",
    "-    \\- -Xmx4096M\n",
    "\n",
    "      JavaVMに4Gバイト以上のメモリを与える。これ未満での動作は保証しておらず，OutOfMemoryエラーが出る。\n",
    "\n",
    "-    \\- -Dlog4j.configureationFile\n",
    "\n",
    "      本プログラムでは内部のロッギングにLog4jを使用している。ログ出力する際にはlog4j2.xmlを作成し，指定すること。\n",
    "\n",
    "      なおサンプルは `log4j2.xml <https://github.com/digital-go-jp/kanjikana-model/core/log4j2.xml>`_ に記載している。\n",
    "\n",
    "-    \\- classpath\n",
    "\n",
    "      Jarファイルまでのパスを記述する。なお，環境変数CLASSPATHにJarファイルまでのパスを記載した場合には本項目不要である。\n",
    "\n",
    "### プログラムオプション\n",
    "  \n",
    "-    \\--infile（デフォルト：input.txt）\n",
    "      \n",
    "      入力ファイル名を指定すること。\n",
    "\n",
    "-    \\--outfile（デフォルト：output.txt）\n",
    "\n",
    "      出力ファイル名を指定すること。\n",
    "\n",
    "-   \\--kanji_idx（デフォルト：1）\n",
    "\n",
    "      入力ファイル内における，漢字・アルファベット姓名の列の位置を指定する。１列目は0を指定し，以下，2列目は１という形で，指定すること。\n",
    "\n",
    "-   \\--kana_idx（デフォルト：2）\n",
    "\n",
    "      入力ファイル内における，カタカナ姓名の列の位置を指定する。１列目は0を指定し，以下，2列目は１という形で，指定すること。\n",
    "\n",
    "-    \\--sep（デフォルト：csv）\n",
    "\n",
    "      入力ファイル及び出力ファイルの列の区切り文字。csvかtsvを指定する。\n",
    "\n",
    "-    \\--thread_num（デフォルト：1）\n",
    "\n",
    "      大量入力データなどの時に，計算を多重化して行う場合には2以上の値を指定する。CPUの数以下を推奨。1を設定した場合には多重化処理を行わない。なお，1超の値を入力した際には，出力ファイル名の末尾に\".数字\"がついたファイルが，thread_numで指定した数だけ作成される。\n",
    "      \n",
    "-    \\--has_header（デフォルト：true）\n",
    "\n",
    "      入力ファイルの１行目をヘッダ行の場合にはtrue，１行目のデータの場合にはfalseを指定する。trueを指定した際には，出力ファイルの１行目にヘッダ行が出力される。\n",
    "\n",
    "-    \\--strategy（デフォルト：ENSEMBLE）\n",
    "\n",
    "      氏名漢字カナ突合に使用する，ストラテジを指定する。\n",
    "      \n",
    "\n",
    "        |ストラテジ          | 内容                                                                                                                                        |\n",
    "        |:----------------------|:--------------------------------------------------------------------------------------------------------------------------|\n",
    "        BASIC                  | 信頼度の高い辞書を用いて判定\n",
    "        ENSEMBLE      |BASICを実行し，NGとなったものに対して，信頼度の高くないモデル(AI,辞書,統計)で多数決\n",
    "        ONLY_AI       |ENSEMBLE内のAIモデルのみで判定\n",
    "        ONLY_DICT     |ENSEMBLE内の辞書モデルのみで判定\n",
    "        ONLY_STAT     |ENSEMBLE内の統計モデルのみで判定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-23T00:36:42.195322652Z main ERROR Reconfiguration failed: No configuration found for '30946e09' at 'null' in 'null'\n",
      "09:36:42.368 [main] DEBUG ai.djl.repository.zoo.DefaultModelZoo -- Scanning models in repo: class ai.djl.repository.SimpleRepository, file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/encoder.pt\n",
      "09:36:42.374 [main] DEBUG ai.djl.engine.Engine -- Registering EngineProvider: PyTorch\n",
      "09:36:42.375 [main] DEBUG ai.djl.engine.Engine -- Found default engine: PyTorch\n",
      "09:36:42.674 [main] INFO ai.djl.util.Ec2Utils -- DJL will collect telemetry to help us better understand our users’ needs, diagnose issues, and deliver additional features. If you would like to learn more or opt-out please go to: https://docs.djl.ai/docs/telemetry.html for more information.\n",
      "09:36:42.677 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Loading model with Criteria:\n",
      "\tApplication: UNDEFINED\n",
      "\tInput: class ai.djl.ndarray.NDList\n",
      "\tOutput: class ai.djl.ndarray.NDList\n",
      "\tEngine: PyTorch\n",
      "\tModelZoo: ai.djl.localmodelzoo\n",
      "\tNo translator supplied\n",
      "\n",
      "09:36:42.677 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Searching model in specified model zoo: ai.djl.localmodelzoo\n",
      "09:36:42.677 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Checking ModelLoader: ai.djl.localmodelzoo:encoder.pt UNDEFINED [\n",
      "\tai.djl.localmodelzoo/encoder.pt/encoder.pt {}\n",
      "]\n",
      "09:36:42.678 [main] DEBUG ai.djl.repository.MRL -- Preparing artifact: file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/encoder.pt, ai.djl.localmodelzoo/encoder.pt/encoder.pt {}\n",
      "09:36:42.679 [main] DEBUG ai.djl.repository.SimpleRepository -- Skip prepare for local repository.\n",
      "09:36:42.858 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Using cache dir: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64\n",
      "09:36:42.866 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudnn.so.8\n",
      "09:36:42.868 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libc10.so\n",
      "09:36:42.868 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudnn_adv_infer.so.8\n",
      "09:36:42.869 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudnn_cnn_train.so.8\n",
      "09:36:42.880 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudnn_ops_infer.so.8\n",
      "09:36:42.881 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libnvrtc-builtins-6c5639ce.so.12.1\n",
      "09:36:42.881 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libnvrtc-b51b459d.so.12\n",
      "09:36:42.884 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcublas-37d11411.so.12\n",
      "09:36:42.907 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudnn_adv_train.so.8\n",
      "09:36:42.908 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcublasLt-f97bfc2c.so.12\n",
      "09:36:42.908 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libnvToolsExt-847d78f2.so.1\n",
      "09:36:42.908 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudnn_ops_train.so.8\n",
      "09:36:42.908 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudnn_cnn_infer.so.8\n",
      "09:36:42.908 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libgomp-52f2fd74.so.1\n",
      "09:36:42.909 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcudart-9335f6a2.so.12\n",
      "09:36:42.909 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libcaffe2_nvrtc.so\n",
      "09:36:42.909 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libtorch_cpu.so\n",
      "09:36:43.362 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libc10_cuda.so\n",
      "09:36:43.362 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libtorch_cuda.so\n",
      "09:36:43.362 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libnvfuser_codegen.so\n",
      "09:36:43.362 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/libtorch.so\n",
      "09:36:43.362 [main] DEBUG ai.djl.pytorch.jni.LibUtils -- Loading native library: /home/analysis01/.djl.ai/pytorch/2.1.1-cu121-linux-x86_64/0.27.0-libdjl_torch.so\n",
      "09:36:43.372 [main] INFO ai.djl.pytorch.engine.PtEngine -- PyTorch graph executor optimizer is enabled, this may impact your inference latency and throughput. See: https://docs.djl.ai/docs/development/inference_performance_optimization.html#graph-executor-optimization\n",
      "09:36:43.374 [main] INFO ai.djl.pytorch.engine.PtEngine -- Number of inter-op threads is 8\n",
      "09:36:43.374 [main] INFO ai.djl.pytorch.engine.PtEngine -- Number of intra-op threads is 8\n",
      "09:36:45.345 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- mapLocation: false\n",
      "09:36:45.345 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- extraFileKeys: []\n",
      "09:36:45.573 [main] DEBUG ai.djl.repository.zoo.DefaultModelZoo -- Scanning models in repo: class ai.djl.repository.SimpleRepository, file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/decoder.pt\n",
      "09:36:45.573 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Loading model with Criteria:\n",
      "\tApplication: UNDEFINED\n",
      "\tInput: class ai.djl.ndarray.NDList\n",
      "\tOutput: class ai.djl.ndarray.NDList\n",
      "\tEngine: PyTorch\n",
      "\tModelZoo: ai.djl.localmodelzoo\n",
      "\tNo translator supplied\n",
      "\n",
      "09:36:45.573 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Searching model in specified model zoo: ai.djl.localmodelzoo\n",
      "09:36:45.573 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Checking ModelLoader: ai.djl.localmodelzoo:decoder.pt UNDEFINED [\n",
      "\tai.djl.localmodelzoo/decoder.pt/decoder.pt {}\n",
      "]\n",
      "09:36:45.573 [main] DEBUG ai.djl.repository.MRL -- Preparing artifact: file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/decoder.pt, ai.djl.localmodelzoo/decoder.pt/decoder.pt {}\n",
      "09:36:45.574 [main] DEBUG ai.djl.repository.SimpleRepository -- Skip prepare for local repository.\n",
      "09:36:45.574 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- mapLocation: false\n",
      "09:36:45.574 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- extraFileKeys: []\n",
      "09:36:45.762 [main] DEBUG ai.djl.repository.zoo.DefaultModelZoo -- Scanning models in repo: class ai.djl.repository.SimpleRepository, file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/positional_encoding.pt\n",
      "09:36:45.762 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Loading model with Criteria:\n",
      "\tApplication: UNDEFINED\n",
      "\tInput: class ai.djl.ndarray.NDList\n",
      "\tOutput: class ai.djl.ndarray.NDList\n",
      "\tEngine: PyTorch\n",
      "\tModelZoo: ai.djl.localmodelzoo\n",
      "\tNo translator supplied\n",
      "\n",
      "09:36:45.762 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Searching model in specified model zoo: ai.djl.localmodelzoo\n",
      "09:36:45.762 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Checking ModelLoader: ai.djl.localmodelzoo:positional_encoding.pt UNDEFINED [\n",
      "\tai.djl.localmodelzoo/positional_encoding.pt/positional_encoding.pt {}\n",
      "]\n",
      "09:36:45.762 [main] DEBUG ai.djl.repository.MRL -- Preparing artifact: file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/positional_encoding.pt, ai.djl.localmodelzoo/positional_encoding.pt/positional_encoding.pt {}\n",
      "09:36:45.762 [main] DEBUG ai.djl.repository.SimpleRepository -- Skip prepare for local repository.\n",
      "09:36:45.763 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- mapLocation: false\n",
      "09:36:45.763 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- extraFileKeys: []\n",
      "09:36:45.770 [main] DEBUG ai.djl.repository.zoo.DefaultModelZoo -- Scanning models in repo: class ai.djl.repository.SimpleRepository, file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/generator.pt\n",
      "09:36:45.770 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Loading model with Criteria:\n",
      "\tApplication: UNDEFINED\n",
      "\tInput: class ai.djl.ndarray.NDList\n",
      "\tOutput: class ai.djl.ndarray.NDList\n",
      "\tEngine: PyTorch\n",
      "\tModelZoo: ai.djl.localmodelzoo\n",
      "\tNo translator supplied\n",
      "\n",
      "09:36:45.770 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Searching model in specified model zoo: ai.djl.localmodelzoo\n",
      "09:36:45.770 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Checking ModelLoader: ai.djl.localmodelzoo:generator.pt UNDEFINED [\n",
      "\tai.djl.localmodelzoo/generator.pt/generator.pt {}\n",
      "]\n",
      "09:36:45.770 [main] DEBUG ai.djl.repository.MRL -- Preparing artifact: file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/generator.pt, ai.djl.localmodelzoo/generator.pt/generator.pt {}\n",
      "09:36:45.770 [main] DEBUG ai.djl.repository.SimpleRepository -- Skip prepare for local repository.\n",
      "09:36:45.771 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- mapLocation: false\n",
      "09:36:45.771 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- extraFileKeys: []\n",
      "09:36:45.773 [main] DEBUG ai.djl.repository.zoo.DefaultModelZoo -- Scanning models in repo: class ai.djl.repository.SimpleRepository, file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/src_tok_emb.pt\n",
      "09:36:45.773 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Loading model with Criteria:\n",
      "\tApplication: UNDEFINED\n",
      "\tInput: class ai.djl.ndarray.NDList\n",
      "\tOutput: class ai.djl.ndarray.NDList\n",
      "\tEngine: PyTorch\n",
      "\tModelZoo: ai.djl.localmodelzoo\n",
      "\tNo translator supplied\n",
      "\n",
      "09:36:45.773 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Searching model in specified model zoo: ai.djl.localmodelzoo\n",
      "09:36:45.773 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Checking ModelLoader: ai.djl.localmodelzoo:src_tok_emb.pt UNDEFINED [\n",
      "\tai.djl.localmodelzoo/src_tok_emb.pt/src_tok_emb.pt {}\n",
      "]\n",
      "09:36:45.773 [main] DEBUG ai.djl.repository.MRL -- Preparing artifact: file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/src_tok_emb.pt, ai.djl.localmodelzoo/src_tok_emb.pt/src_tok_emb.pt {}\n",
      "09:36:45.774 [main] DEBUG ai.djl.repository.SimpleRepository -- Skip prepare for local repository.\n",
      "09:36:45.774 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- mapLocation: false\n",
      "09:36:45.774 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- extraFileKeys: []\n",
      "09:36:45.778 [main] DEBUG ai.djl.repository.zoo.DefaultModelZoo -- Scanning models in repo: class ai.djl.repository.SimpleRepository, file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/tgt_tok_emb.pt\n",
      "09:36:45.778 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Loading model with Criteria:\n",
      "\tApplication: UNDEFINED\n",
      "\tInput: class ai.djl.ndarray.NDList\n",
      "\tOutput: class ai.djl.ndarray.NDList\n",
      "\tEngine: PyTorch\n",
      "\tModelZoo: ai.djl.localmodelzoo\n",
      "\tNo translator supplied\n",
      "\n",
      "09:36:45.778 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Searching model in specified model zoo: ai.djl.localmodelzoo\n",
      "09:36:45.778 [main] DEBUG ai.djl.repository.zoo.ModelZoo -- Checking ModelLoader: ai.djl.localmodelzoo:tgt_tok_emb.pt UNDEFINED [\n",
      "\tai.djl.localmodelzoo/tgt_tok_emb.pt/tgt_tok_emb.pt {}\n",
      "]\n",
      "09:36:45.778 [main] DEBUG ai.djl.repository.MRL -- Preparing artifact: file:/home/analysis01/src/kanjikana-model/sample/inference_java/../training/model/tgt_tok_emb.pt, ai.djl.localmodelzoo/tgt_tok_emb.pt/tgt_tok_emb.pt {}\n",
      "09:36:45.778 [main] DEBUG ai.djl.repository.SimpleRepository -- Skip prepare for local repository.\n",
      "09:36:45.779 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- mapLocation: false\n",
      "09:36:45.779 [main] DEBUG ai.djl.pytorch.jni.JniUtils -- extraFileKeys: []\n"
     ]
    }
   ],
   "source": [
    "!java -Xmx4096M -Dlog4j.configurationFile=log4j2.xml -classpath target/java_sample-1.0-jar-with-dependencies.jar jp.go.digital.sample.Main --test_file ../dataset/test.jsonl --model_script=\"../training/model/script.pt\" --model_encoder=\"../training/model/encoder.pt\" --model_decoder=\"../training/model/decoder.pt\" --model_positional_encoding=\"../training/model/positional_encoding.pt\" --model_generator=\"../training/model/generator.pt\" --model_src_tok_emb=\"../training/model/src_tok_emb.pt\" --model_tgt_tok_emb=\"../training/model/tgt_tok_emb.pt\" --model_vocab_src=\"../training/model/vocab_src.txt\" --model_vocab_tgt=\"../training/model/vocab_tgt.txt\" --model_params=\"../training/model/params.json\" --out_file=\"output.txt\" --n_best=5 --beam_width=5 --max_len=100 --search_type=\"greedy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論結果の評価\n",
    "\n",
    "推論で出力された翻訳結果を、Bleuスコアで評価する。\n",
    "\n",
    "### 出力結果\n",
    "出力のoutput.txtはTSV形式で下記の用に保存されている。\n",
    "\n",
    "\n",
    "```tsv\n",
    "no\tsearch\tsrc\ttgt\tpred\tprob\n",
    "0\tgreedy\tA new difficulty has arisen.\tUne nouvelle difficulté est apparue.\tUn peu de mon amis de l'aide.\t-25.770613057685175\n",
    "1\tgreedy\tIt's not going to end well.\tÇa ne va pas bien se terminer.\tCe n'est pas le faire de la maison.\t-16.37295488919627\n",
    "```\n",
    "各項目は次の通りである。\n",
    "- no    \n",
    "通し番号\n",
    "\n",
    "- search    \n",
    "サーチのタイプ。今回はgreedyサーチ\n",
    "\n",
    "- src    \n",
    "モデルへの入力文章\n",
    "\n",
    "- tgt     \n",
    "翻訳の正解\n",
    "\n",
    "- pred    \n",
    "greedyサーチによって出力された推論結果\n",
    "\n",
    "- prob    \n",
    "predで出力された文章のモデルから出力された確率\n",
    "\n",
    "\n",
    "### 評価\n",
    "NLTKライブラリを用いて、評価を行う\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://thepythoncode.com/article/bleu-score-in-python\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文を単語に分割する\n",
    "def normalize(s):\n",
    "    # 記号削除\n",
    "    s = re.sub(\"[^a--zA-Z]\",\" \",s)\n",
    "\n",
    "    # 小文字にする\n",
    "    s = s.lower()\n",
    "\n",
    "    # 単語単位に分ける\n",
    "    lst = word_tokenize(s)\n",
    "\n",
    "    # stopword削除\n",
    "    lst = [ w for w in s if not w in set(stopwords.words('french'))]\n",
    "\n",
    "    # remmatize\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    lst = [lemma.lemmatize(w) for w in lst]\n",
    "\n",
    "    return lst\n",
    "\n",
    "with open('output.txt','r',encoding='utf-8') as f:\n",
    "    lst = [l.rstrip() for l in f]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
