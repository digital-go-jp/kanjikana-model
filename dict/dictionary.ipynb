{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ\n",
    "次の辞書ファイルを作成する\n",
    "\n",
    "## 姓名辞書\n",
    "- oss.json\n",
    "オープンソースの辞書から作成した，漢字・アルファベットとカタカナのペアデータ\n",
    "- seimei.json\n",
    "ダウンロードしたWebデータ（Wikipedia）から作成した漢字・アルファベットとカタカナのペアのデータ\n",
    "\n",
    "## 単漢字辞書\n",
    "- tankanji.json\n",
    "オープンソースの辞書から作成した，単漢字とカタカナのペアデータ\n",
    "\n",
    "## 異体字辞書\n",
    "- itaiji.json\n",
    "オープンソースの辞書から作成した，異体字の漢字のペアデータ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# データを準備する\n",
    "\n",
    "辞書用及び。AI用のデータを，オープンソースのデータからダウンロードし，整形する。\n",
    "使用するデータソースは次のとおり      \n",
    "\n",
    "## データソース一覧\n",
    "\n",
    "### 辞書データ\n",
    "- [canna](https://osdn.dl.osdn.net/canna/)\n",
    "- [freewnn](https://osdn.dl.osdn.net/freewnn/)\n",
    "- [ipadic](https://taku910.github.io/mecab/)\n",
    "- [kakasi](http://kakasi.namazu.org/)\n",
    "- [mozc](https://github.com/google/mozc/)\n",
    "- [neologd](https://github.com/neologd/mecab-ipadic-neologd/)\n",
    "- [skk](https://github.com/skk-dev/dict/)\n",
    "\n",
    "### Webデータ\n",
    "- [wikipedia](https://dumps.wikimedia.org/)\n",
    "\n",
    "## データ形式について\n",
    "データは，単語辞書，単漢字辞書，異体字辞書をそれぞれのデータソースから作成する。\n",
    "作成するデータフォーマットはJSON形式であり，項目については次のとおり。\n",
    "\n",
    "### 姓名辞書\n",
    "単語漢字をキーとし，その読みのカタカナをキーとするハッシュテーブルをバリューとして追加する。またカタカナにはそれぞれdicsというキーで，漢字とカタカナのペアが存在する，データソースの一覧を保持している。\n",
    "```json\n",
    "{ \n",
    "    \"単語漢字１\" :{\n",
    "        \"カタカナ１\":{\n",
    "            \"dics\":[\n",
    "                \"freewnn\",\n",
    "                \"canna\"\n",
    "            ]\n",
    "        },\n",
    "        \"カタカナ２\":{\n",
    "            \"dics\":{\n",
    "                \"canna\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"単語漢字２\":{\n",
    "        ..\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "### 単漢字辞書\n",
    "単漢字をキーとし，その読みのカタカナをキーとするハッシュテーブルをバリューとして追加する。またカタカナにはそれぞれdicsというキーで，漢字とカタカナのペアが存在する，データソースの一覧を保持している。\n",
    "```json\n",
    "{ \n",
    "    \"単漢字１\" :{\n",
    "        \"カタカナ１\":{\n",
    "            \"dics\":[\n",
    "                \"freewnn\",\n",
    "                \"canna\"\n",
    "            ]\n",
    "        },\n",
    "        \"カタカナ２\":{\n",
    "            \"dics\":{\n",
    "                \"canna\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"単漢字２\":{\n",
    "        ..\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### 異体字辞書\n",
    "単漢字をキーとし，その異体字である単漢字をキーとするハッシュテーブルをバリューとして追加する。また異体字である単漢字にはそれぞれdicsというキーで，漢字とカタカナのペアが存在する，データソースの一覧を保持している。\n",
    "\n",
    "```json\n",
    "{ \n",
    "    \"単漢字１\" :{\n",
    "        \"異体字１\":{\n",
    "            \"dics\":[\n",
    "                \"kakasi\",\n",
    "                \"mozc\"\n",
    "            ]\n",
    "        },\n",
    "        \"異体字２\":{\n",
    "            \"dics\":{\n",
    "                \"skk\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"単漢字２\":{\n",
    "        ..\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "## 事前準備\n",
    "pythonで必要なライブラリ群をインストールしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning off\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ver']='1.6.2o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] そのようなファイルやディレクトリはありません: '../requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /home/analysis01/src/kanjikana-private/venv/lib/python3.11/site-packages (3.2)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データをダウンロードし，漢字とカタカナを抜き出す\n",
    "あらかじめ，nkfコマンドをインストールしておく必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## canna\n",
    "cannnaからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/canna\n",
      "^C\n",
      "bunzip2: Can't open input file Canna37p3.tar.bz2: No such file or directory.\n",
      "tar: Canna37p3.tar: open 不能: そのようなファイルやディレクトリはありません\n",
      "tar: Error is not recoverable: exiting now\n",
      "bzip2: Can't open input file Canna37p3.tar: No such file or directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd canna\n",
    "!wget -nc -q \"https://osdn.dl.osdn.net/canna/9565/Canna37p3.tar.bz2\" --no-check-certificate;\n",
    "!bunzip2 Canna37p3.tar.bz2;\n",
    "!tar xfp Canna37p3.tar;\n",
    "!bzip2 Canna37p3.tar;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_canna.py --indir Canna37p3/dic/ideo/pubdic --outfile extract.txt\n",
    "!python words.py --indir \"Canna37p3/dic/ideo/words\" --outfile words.txt\n",
    "!cat extract.txt words.txt > dict.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannaのダウンロードデータを削除する\n",
    "!rm -rf Canna37p3\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## freewnn\n",
    "freewnnからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd freewnn\n",
    "!wget -nc -q https://osdn.dl.osdn.net/freewnn/63271/FreeWnn-1.1.1-a023.tar.gz --no-check-certificate\n",
    "!tar zxfp FreeWnn-1.1.1-a023.tar.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_freewnn.py --infile FreeWnn-1.1.1-a023/PubdicPlus/pubdic.p --outfile dict.txt\n",
    "!rm -rf FreeWnn-1.1.1-a023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# freewnnのダウンロードデータを削除する\n",
    "!rm -rf FreeWnn-1.1.1-a023\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ipadic\n",
    "ipadicからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ipadic\n",
    "!wget -nc -q --no-check-certificate  \"https://ja.osdn.net/frs/g_redir.php?m=ipconnect&f=mecab%2Fmecab-ipadic%2F2.7.0-20070801%2Fmecab-ipadic-2.7.0-20070801.tar.gz\" -O mecab-ipadic-2.7.0-20070801.tar.gz\n",
    "!tar zxfp mecab-ipadic-2.7.0-20070801.tar.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_ipadic.py --indir=\"mecab-ipadic-2.7.0-20070801/\" --outfile=\"dict.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロードデータを削除する\n",
    "!rm -rf mecab-ipadic-2.7.0-20070801\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kakasi\n",
    "kakasiからは，単語辞書と単漢字辞書，異体字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd kakasi\n",
    "!wget -nc -q http://kakasi.namazu.org/stable/kakasi-2.3.6.tar.gz --no-check-certificate\n",
    "!tar zxfp kakasi-2.3.6.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python dict_kakasi.py --infile=\"kakasi-2.3.6/kakasidict\" --outfile=\"dict.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異体字辞書を作成する\n",
    "!python  itaiji_kakasi.py --infile=\"kakasi-2.3.6/itaijidict\" --outfile=\"itaiji.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロードデータを削除する\n",
    "!rm -rf kakasi-2.3.6\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mozc\n",
    "mozcからは，単語辞書と単漢字辞書，異体字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd mozc\n",
    "!wget -nc -q \"https://github.com/google/mozc/archive/refs/tags/2.29.5268.102.tar.gz\" --no-check-certificate\n",
    "!tar xfpz 2.29.5268.102.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語辞書を作成する\n",
    "!python extract_mozc.py --indir=\"mozc-2.29.5268.102/src/data/dictionary_oss/\" --outfile=\"dict1.txt\"\n",
    "!python extract_oss.py --indir=\"mozc-2.29.5268.102/src/data/oss/\" --outfile=\"dict2.txt\"\n",
    "!cat dict1.txt dict2.txt > dict.txt\n",
    "!rm -rf dict1.txt dict2.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単漢字辞書を作成する\n",
    "!python extract_single.py --indir=\"mozc-2.29.5268.102/src/data/single_kanji/\" --outfile=\"tankanji.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異体字辞書を作成する \n",
    "!python extract_variant.py --indir=\"mozc-2.29.5268.102/src/data/single_kanji/\" --outfile=\"itaiji.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要ファイルを削除する\n",
    "!rm -rf mozc-2.29.5268.102\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neologd\n",
    "ipadicからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd neologd\n",
    "!wget -nc -q https://github.com/neologd/mecab-ipadic-neologd/archive/refs/tags/v0.0.7.tar.gz --no-check-certificate\n",
    "!tar zxf v0.0.7.tar.gz\n",
    "!xz --decompress  mecab-ipadic-neologd-0.0.7/seed/*xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_neologd.py --indir=\"mecab-ipadic-neologd-0.0.7/seed\" --outfile=\"dict.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要ファイルを削除する\n",
    "\n",
    "!rm -rf mecab-ipadic-neologd-0.0.7\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skk\n",
    "単語辞書と異体字辞書，単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd skk\n",
    "!wget -nc -q \"https://github.com/skk-dev/dict/raw/master/SKK-JISYO.jinmei\" --no-check-certificate\n",
    "!wget -nc -q \"https://github.com/skk-dev/dict/raw/master/SKK-JISYO.fullname\" --no-check-certificate\n",
    "!wget -nc -q https://github.com/skk-dev/dict/raw/master/SKK-JISYO.itaiji --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 姓名辞書を作成する\n",
    "!python jinmei.py --infile SKK-JISYO.jinmei --outfile skk_jinmei.txt\n",
    "!python fullname.py --infile SKK-JISYO.fullname --outfile skk_fullname.txt\n",
    "!cat skk_jinmei.txt skk_fullname.txt > dict.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単漢字辞書を作成する\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異体字辞書を作成する\n",
    "!python itaiji_skk.py --infile SKK-JISYO.itaiji  --outfile itaiji.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要ファイルを削除する\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikipedia\n",
    "wikipediaからは，概要部分を抜き出して，文頭に　「漢字（読み）・・」　と記載されている場合に，漢字と読み仮名のペアを抜き出す。多少間違えている可能性があるので注意。\n",
    "\n",
    "\n",
    "Wikipediaの構造解析から，Abstract部分に着目する\n",
    "\n",
    "'''アルマ・マリア・マーラー＝ヴェルフェル'''（'''Alma Maria Mahler-Werfel''', [[1879年]][[8月31日]] – [[1964年]][[12月11日]]）は、[[オーストリア]]の作曲家[[グス\n",
    "タフ・マーラー]]の妻。結婚前の姓はシンドラー（Schindler）。自身も作曲を行い、16>の歌曲が今日に残されている。華麗な男性遍歴で知られる。 \n",
    "\n",
    "\n",
    "こんな形で入っている行をまずは抜き出す。     \n",
    "- 見出しの最初に，'''人名'''\n",
    "- ()の中に'''読み'''が入っている\n",
    "- ()の中に[[yyyy年]]\n",
    "- ()の中に[[mm月dd日]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd wikipedia\n",
    "!wget -nc -q https://dumps.wikimedia.org/jawiki/latest/jawiki-latest-pages-articles.xml.bz2 --no-check-certificate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipediaから概要だけを抜き出す\n",
    "!python extract_wiki.py --infile=\"jawiki-latest-pages-articles.xml.bz2\" --outfile=\"abstract.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 漢字とカナのペアとなるものと推測されるものを抜き出す。\n",
    "!python extract_name.py --outfile=\"abstract_name.txt\" --infile=\"abstract.txt\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_name.pyによってWikipediaのダンプファイルから，概要部分が抜き出されたものに対して，漢字・アルファベットとカタカナのペアのうち，正しいと推測されるものを選択する。\n",
    "!python select_name.py --infile abstract_name.txt --outfile wikiname.txt --ngfile ng.txt;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_name.pyによってWikipediaのダンプファイルから作成した漢字・アルファベットとカタカナのペアを単語単位に分割する\n",
    "!python dict_name.py --infile wikiname.txt --outfile dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要ファイル削除\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ダウンロードしたデータから辞書を作成する\n",
    "\n",
    "## オープンソース辞書データ\n",
    "オープンソースの辞書から抜き出したデータで，oss.json,tankanji.json, itaiji.jsonを作成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver=os.environ['ver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/data_$ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oss.json\n",
    "!rm -rf data/data_$ver/oss_$ver.json\n",
    "!python merge.py --infile canna/dict.txt --jsonfile data/data_$ver/oss_$ver.json --dicname canna;\n",
    "!python merge.py --infile freewnn/dict.txt --jsonfile data/data_$ver/oss_$ver.json --dicname freewnn;\n",
    "!python merge.py --infile ipadic/dict.txt --jsonfile data/data_$ver/oss_$ver.json --dicname ipadic;\n",
    "!python merge.py --infile kakasi/dict.txt --jsonfile data/data_$ver/oss_$ver.json --dicname kakasi;\n",
    "!python merge.py --infile mozc/dict.txt --jsonfile data/data_$ver/oss_$ver.json --dicname mozc;\n",
    "!python merge.py --infile neologd/dict.txt --jsonfile data/data_$ver/oss_$ver.json --dicname neologd;\n",
    "!python merge.py --infile skk/dict.txt --jsonfile data/data_$ver/oss_$ver.json --dicname skk;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tankanji.json\n",
    "!rm -rf data/data_$ver/tankanji_$ver.json\n",
    "\n",
    "!python merge.py --infile canna/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname canna;\n",
    "!python merge.py --infile freewnn/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname freewnn;\n",
    "!python merge.py --infile ipadic/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname ipadic;\n",
    "!python merge.py --infile kakasi/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname kakasi;\n",
    "!python merge.py --infile mozc/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname mozc;\n",
    "!python merge.py --infile neologd/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname neologd;\n",
    "!python merge.py --infile skk/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname skk;\n",
    "!python merge.py --infile mj/tankanji.txt --jsonfile data/data_$ver/tankanji_$ver.json --dicname mj;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itaiji.json\n",
    "!rm -rf data/data_$ver/itaiji_$ver.json\n",
    "!python merge.py --infile kakasi/itaiji.txt --jsonfile data/data_$ver/itaiji_$ver.json --dicname kakasi\n",
    "!python merge.py --infile mozc/itaiji.txt --jsonfile data/data_$ver/itaiji_$ver.json --dicname mozc\n",
    "!python merge.py --infile skk/itaiji.txt --jsonfile data/data_$ver/itaiji_$ver.json --dicname skk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webデータ\n",
    "wikipediaから抜き出したデータから，姓名の漢字とカナのペアで，seimei.jsonを作成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd wikipedia\n",
    "\n",
    "# オープンソースの辞書のデータに入っていない漢字とカナのペアを抜き出す\n",
    "!python check_dict.py --infile dict.txt --outfile dict_add.txt --oss ../data/data_$ver/oss_$ver.json;\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/data_$ver/seimei_$ver.json\n",
    "!python merge.py --infile wikipedia/dict.txt --jsonfile data/data_$ver/seimei_$ver.json --dicname wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他\n",
    "その他，氏名漢字カナ突合モデルに必要な空ファイルを作成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(f\"data/data_{ver}/crawl_{ver}.json\",'w',encoding='utf-8') as f:\n",
    "    f.write(\"{}\")\n",
    "\n",
    "with open(f\"data/data_{ver}/statistics_{ver}.json\",'w',encoding='utf-8') as f:\n",
    "    f.write(\"{}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
