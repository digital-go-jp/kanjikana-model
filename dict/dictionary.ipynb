{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ\n",
    "次の辞書ファイルを作成する\n",
    "\n",
    "## 姓名辞書\n",
    "- oss.json\n",
    "オープンソースの辞書から作成した，漢字・アルファベットとカタカナのペアデータ\n",
    "- seimei.json\n",
    "ダウンロードしたWebデータ（Wikipedia）から作成した漢字・アルファベットとカタカナのペアのデータ\n",
    "\n",
    "## 単漢字辞書\n",
    "- tankanji.json\n",
    "オープンソースの辞書から作成した，単漢字とカタカナのペアデータ\n",
    "\n",
    "## 異体字辞書\n",
    "- itaiji.json\n",
    "オープンソースの辞書から作成した，異体字の漢字のペアデータ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# データを準備する\n",
    "\n",
    "辞書用及び。AI用のデータを，オープンソースのデータからダウンロードし，整形する。\n",
    "使用するデータソースは次のとおり      \n",
    "\n",
    "## データソース一覧\n",
    "\n",
    "### オープンソース辞書データ\n",
    "- [canna](https://osdn.dl.osdn.net/canna/)\n",
    "- [freewnn](https://osdn.dl.osdn.net/freewnn/)\n",
    "- [ipadic](https://taku910.github.io/mecab/)\n",
    "- [kakasi](http://kakasi.namazu.org/)\n",
    "- [mj](https://moji.or.jp/)\n",
    "- [mozc](https://github.com/google/mozc/)\n",
    "- [neologd](https://github.com/neologd/mecab-ipadic-neologd/)\n",
    "- [skk](https://github.com/skk-dev/dict/)\n",
    "\n",
    "### Webデータ\n",
    "- [wikipedia](https://dumps.wikimedia.org/)\n",
    "\n",
    "## データ形式について\n",
    "データは，単語辞書，単漢字辞書，異体字辞書をそれぞれのデータソースから作成する。\n",
    "作成するデータフォーマットはJSON形式であり，項目については次のとおり。\n",
    "\n",
    "### 姓名辞書\n",
    "単語漢字をキーとし，その読みのカタカナをキーとするハッシュテーブルをバリューとして追加する。またカタカナにはそれぞれdicsというキーで，漢字とカタカナのペアが存在する，データソースの一覧を保持している。\n",
    "```json\n",
    "{ \n",
    "    \"単語漢字１\" :{\n",
    "        \"カタカナ１\":{\n",
    "            \"dics\":[\n",
    "                \"freewnn\",\n",
    "                \"canna\"\n",
    "            ]\n",
    "        },\n",
    "        \"カタカナ２\":{\n",
    "            \"dics\":{\n",
    "                \"canna\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"単語漢字２\":{\n",
    "        ..\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "### 単漢字辞書\n",
    "単漢字をキーとし，その読みのカタカナをキーとするハッシュテーブルをバリューとして追加する。またカタカナにはそれぞれdicsというキーで，漢字とカタカナのペアが存在する，データソースの一覧を保持している。\n",
    "```json\n",
    "{ \n",
    "    \"単漢字１\" :{\n",
    "        \"カタカナ１\":{\n",
    "            \"dics\":[\n",
    "                \"freewnn\",\n",
    "                \"canna\"\n",
    "            ]\n",
    "        },\n",
    "        \"カタカナ２\":{\n",
    "            \"dics\":{\n",
    "                \"canna\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"単漢字２\":{\n",
    "        ..\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### 異体字辞書\n",
    "単漢字をキーとし，その異体字である単漢字をキーとするハッシュテーブルをバリューとして追加する。また異体字である単漢字にはそれぞれdicsというキーで，漢字とカタカナのペアが存在する，データソースの一覧を保持している。\n",
    "\n",
    "```json\n",
    "{ \n",
    "    \"単漢字１\" :{\n",
    "        \"異体字１\":{\n",
    "            \"dics\":[\n",
    "                \"kakasi\",\n",
    "                \"mozc\"\n",
    "            ]\n",
    "        },\n",
    "        \"異体字２\":{\n",
    "            \"dics\":{\n",
    "                \"skk\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"単漢字２\":{\n",
    "        ..\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "## 事前準備\n",
    "pythonで必要なライブラリ群をインストールしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning off\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.1.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: alabaster==1.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: attrs==24.3.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 5)) (24.3.0)\n",
      "Requirement already satisfied: babel==2.16.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 6)) (2.16.0)\n",
      "Requirement already satisfied: blockdiag==3.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: cattrs==24.1.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 8)) (24.1.2)\n",
      "Requirement already satisfied: certifi==2024.12.14 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 9)) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 11)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.11 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 12)) (1.8.11)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 13)) (5.1.1)\n",
      "Requirement already satisfied: doc8==1.1.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 14)) (1.1.2)\n",
      "Requirement already satisfied: docutils==0.21.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 15)) (0.21.2)\n",
      "Requirement already satisfied: esbonio==0.16.5 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 16)) (0.16.5)\n",
      "Requirement already satisfied: executing==2.1.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 17)) (2.1.0)\n",
      "Requirement already satisfied: filelock==3.16.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 18)) (3.16.1)\n",
      "Requirement already satisfied: fsspec==2024.10.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 19)) (2024.10.0)\n",
      "Requirement already satisfied: funcparserlib==2.0.0a0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 20)) (2.0.0a0)\n",
      "Requirement already satisfied: grpcio==1.68.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 21)) (1.68.1)\n",
      "Requirement already satisfied: idna==3.10 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 22)) (3.10)\n",
      "Requirement already satisfied: imagesize==1.4.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 23)) (1.4.1)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 24)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.30.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 25)) (8.30.0)\n",
      "Requirement already satisfied: jaconv==0.4.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 26)) (0.4.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 27)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.4 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 28)) (3.1.4)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 29)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 30)) (5.7.2)\n",
      "Requirement already satisfied: lsprotocol==2023.0.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 31)) (2023.0.1)\n",
      "Requirement already satisfied: lxml==5.3.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 32)) (5.3.0)\n",
      "Requirement already satisfied: Markdown==3.7 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 33)) (3.7)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 34)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 35)) (0.1.7)\n",
      "Requirement already satisfied: mojimoji==0.0.13 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 36)) (0.0.13)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 37)) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 38)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 39)) (3.4.2)\n",
      "Requirement already satisfied: numpy==2.2.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 40)) (2.2.0)\n",
      "Requirement already satisfied: packaging==24.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 41)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 42)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 43)) (0.8.4)\n",
      "Requirement already satisfied: pbr==6.1.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 44)) (6.1.0)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 45)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 46)) (11.0.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 47)) (4.3.6)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 48)) (3.0.48)\n",
      "Requirement already satisfied: protobuf==5.29.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 49)) (5.29.2)\n",
      "Requirement already satisfied: psutil==6.1.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 50)) (6.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 51)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 52)) (0.2.3)\n",
      "Requirement already satisfied: pygls==1.3.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 53)) (1.3.1)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 54)) (2.18.0)\n",
      "Requirement already satisfied: pyspellchecker==0.8.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 55)) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 56)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 57)) (2024.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 58)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 59)) (26.2.0)\n",
      "Requirement already satisfied: regex==2024.11.6 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 60)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 61)) (2.32.3)\n",
      "Requirement already satisfied: restructuredtext_lint==1.4.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 62)) (1.4.0)\n",
      "Requirement already satisfied: seqdiag==3.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 63)) (3.0.0)\n",
      "Requirement already satisfied: setuptools==75.6.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 64)) (75.6.0)\n",
      "Requirement already satisfied: six==1.17.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 65)) (1.17.0)\n",
      "Requirement already satisfied: snowballstemmer==2.2.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 66)) (2.2.0)\n",
      "Requirement already satisfied: Sphinx==8.1.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 67)) (8.1.3)\n",
      "Requirement already satisfied: sphinx-rtd-theme==3.0.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 68)) (3.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp==2.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 69)) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp==2.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 70)) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp==2.1.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 71)) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jquery==4.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 72)) (4.1)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath==1.0.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 73)) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-mermaid==1.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 74)) (1.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp==2.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 75)) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-seqdiag==3.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 76)) (3.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml==2.0.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 77)) (2.0.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 78)) (0.6.3)\n",
      "Requirement already satisfied: stevedore==5.4.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 79)) (5.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 80)) (1.13.1)\n",
      "Requirement already satisfied: tensorboard==2.18.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 81)) (2.18.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 82)) (0.7.2)\n",
      "Requirement already satisfied: torch==2.5.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 83)) (2.5.1)\n",
      "Requirement already satisfied: tornado==6.4.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 84)) (6.4.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 85)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 86)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.2 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 87)) (2024.2)\n",
      "Requirement already satisfied: urllib3==2.3.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 88)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 89)) (0.2.13)\n",
      "Requirement already satisfied: webcolors==24.11.1 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 90)) (24.11.1)\n",
      "Requirement already satisfied: Werkzeug==3.1.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 91)) (3.1.3)\n",
      "Requirement already satisfied: xlsx2csv==0.8.4 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 92)) (0.8.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/analysis01/src/kanjikana-model/venv/lib/python3.11/site-packages (from torch==2.5.1->-r ../requirements.txt (line 83)) (3.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9685 sha256=e45cdc8693709d1d92c95256a204b9c5b8f5876529b0f7d573d113094ec60c80\n",
      "  Stored in directory: /Users/utsubo-katsuhiko/Library/Caches/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データをダウンロードし，漢字とカタカナを抜き出す\n",
    "あらかじめ，nkfコマンドをインストールしておく必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## canna\n",
    "cannnaからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/canna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utsubo-katsuhiko/Documents/GitHub/kanjikana-model/venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd canna\n",
    "!wget -nc -q \"https://osdn.dl.osdn.net/canna/9565/Canna37p3.tar.bz2\" --no-check-certificate;\n",
    "!bunzip2 Canna37p3.tar.bz2;\n",
    "!tar xfp Canna37p3.tar;\n",
    "!bzip2 Canna37p3.tar;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"indir\": \"Canna37p3/dic/ideo/pubdic\",\n",
      "  \"outfile\": \"extract.txt\"\n",
      "}\n",
      "{\n",
      "  \"indir\": \"Canna37p3/dic/ideo/words\",\n",
      "  \"outfile\": \"words.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_canna.py --indir Canna37p3/dic/ideo/pubdic --outfile extract.txt\n",
    "!python words.py --indir \"Canna37p3/dic/ideo/words\" --outfile words.txt\n",
    "!cat extract.txt words.txt > dict.txt\n",
    "!rm -rf extract.txt words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"dict.txt\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# cannaのダウンロードデータを削除する\n",
    "!rm -rf Canna37p3\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## freewnn\n",
    "freewnnからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/freewnn\n"
     ]
    }
   ],
   "source": [
    "%cd freewnn\n",
    "!wget -nc -q https://osdn.dl.osdn.net/freewnn/63271/FreeWnn-1.1.1-a023.tar.gz --no-check-certificate\n",
    "!tar zxfp FreeWnn-1.1.1-a023.tar.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"FreeWnn-1.1.1-a023/PubdicPlus/pubdic.p\",\n",
      "  \"outfile\": \"dict.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_freewnn.py --infile FreeWnn-1.1.1-a023/PubdicPlus/pubdic.p --outfile dict.txt\n",
    "!rm -rf FreeWnn-1.1.1-a023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"dict.txt\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# freewnnのダウンロードデータを削除する\n",
    "!rm -rf FreeWnn-1.1.1-a023\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ipadic\n",
    "ipadicからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/ipadic\n"
     ]
    }
   ],
   "source": [
    "%cd ipadic\n",
    "!wget -nc -q --no-check-certificate  \"https://ja.osdn.net/frs/g_redir.php?m=ipconnect&f=mecab%2Fmecab-ipadic%2F2.7.0-20070801%2Fmecab-ipadic-2.7.0-20070801.tar.gz\" -O mecab-ipadic-2.7.0-20070801.tar.gz\n",
    "!tar zxfp mecab-ipadic-2.7.0-20070801.tar.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"indir\": \"mecab-ipadic-2.7.0-20070801/\",\n",
      "  \"outfile\": \"dict.txt\"\n",
      "}\n",
      "mecab-ipadic-2.7.0-20070801/Adj.csv\n",
      "mecab-ipadic-2.7.0-20070801/Adnominal.csv\n",
      "mecab-ipadic-2.7.0-20070801/Adverb.csv\n",
      "mecab-ipadic-2.7.0-20070801/Auxil.csv\n",
      "mecab-ipadic-2.7.0-20070801/Conjunction.csv\n",
      "mecab-ipadic-2.7.0-20070801/Filler.csv\n",
      "mecab-ipadic-2.7.0-20070801/Interjection.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.adjv.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.adverbal.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.demonst.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.nai.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.name.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.number.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.org.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.others.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.place.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.proper.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.verbal.csv\n",
      "mecab-ipadic-2.7.0-20070801/Others.csv\n",
      "mecab-ipadic-2.7.0-20070801/Postp-col.csv\n",
      "mecab-ipadic-2.7.0-20070801/Postp.csv\n",
      "mecab-ipadic-2.7.0-20070801/Prefix.csv\n",
      "mecab-ipadic-2.7.0-20070801/Suffix.csv\n",
      "mecab-ipadic-2.7.0-20070801/Symbol.csv\n",
      "mecab-ipadic-2.7.0-20070801/Verb.csv\n"
     ]
    }
   ],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_ipadic.py --indir=\"mecab-ipadic-2.7.0-20070801/\" --outfile=\"dict.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"dict.txt\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# ダウンロードデータを削除する\n",
    "!rm -rf mecab-ipadic-2.7.0-20070801\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kakasi\n",
    "kakasiからは，単語辞書と単漢字辞書，異体字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/kakasi\n"
     ]
    }
   ],
   "source": [
    "%cd kakasi\n",
    "!wget -nc -q http://kakasi.namazu.org/stable/kakasi-2.3.6.tar.gz --no-check-certificate\n",
    "!tar zxfp kakasi-2.3.6.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python dict_kakasi.py --infile=\"kakasi-2.3.6/kakasidict\" --outfile=\"dict.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"dict.txt\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異体字辞書を作成する\n",
    "!python  itaiji_kakasi.py --infile=\"kakasi-2.3.6/itaijidict\" --outfile=\"itaiji.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# ダウンロードデータを削除する\n",
    "!rm -rf kakasi-2.3.6\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mj\n",
    "mjからは単漢字辞書を作成する。データはExcel形式で提供されているので，Excel形式をCSV形式へ変換する[xlsx2csv](https://github.com/dilshod/xlsx2csv)を利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/mj\n"
     ]
    }
   ],
   "source": [
    "%cd mj\n",
    "!wget -nc -q https://moji.or.jp/wp-content/uploads/2024/01/mji.00602.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel形式からcsvへ変換する\n",
    "!xlsx2csv mji.00602.xlsx mj.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"mj.csv\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n",
      "cnt=105175\n",
      "len=51673\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する。\n",
    "!python extract_xlsx.py --infile mj.csv --outfile tankanji.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# ダウンロードしたファイルと不要ファイルを削除する\n",
    "!rm -rf *.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mozc\n",
    "kakasiからは，単語辞書と単漢字辞書，異体字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/mozc\n"
     ]
    }
   ],
   "source": [
    "%cd mozc\n",
    "!wget -nc -q \"https://github.com/google/mozc/archive/refs/tags/2.29.5268.102.tar.gz\" --no-check-certificate\n",
    "!tar xfpz 2.29.5268.102.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"indir\": \"mozc-2.29.5268.102/src/data/dictionary_oss/\",\n",
      "  \"outfile\": \"dict1.txt\"\n",
      "}\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary00.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary01.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary02.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary03.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary04.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary05.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary06.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary07.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary08.txt\n",
      "mozc-2.29.5268.102/src/data/dictionary_oss/dictionary09.txt\n",
      "{\n",
      "  \"indir\": \"mozc-2.29.5268.102/src/data/oss/\",\n",
      "  \"outfile\": \"dict2.txt\"\n",
      "}\n",
      "mozc-2.29.5268.102/src/data/oss//aux_dictionary.tsv\n"
     ]
    }
   ],
   "source": [
    "# 単語辞書を作成する\n",
    "!python extract_mozc.py --indir=\"mozc-2.29.5268.102/src/data/dictionary_oss/\" --outfile=\"dict1.txt\"\n",
    "!python extract_oss.py --indir=\"mozc-2.29.5268.102/src/data/oss/\" --outfile=\"dict2.txt\"\n",
    "!cat dict1.txt dict2.txt > dict.txt\n",
    "!rm -rf dict1.txt dict2.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"indir\": \"mozc-2.29.5268.102/src/data/single_kanji/\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n",
      "mozc-2.29.5268.102/src/data/single_kanji//single_kanji.tsv\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する\n",
    "!python extract_single.py --indir=\"mozc-2.29.5268.102/src/data/single_kanji/\" --outfile=\"tankanji.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"indir\": \"mozc-2.29.5268.102/src/data/single_kanji/\",\n",
      "  \"outfile\": \"itaiji.txt\"\n",
      "}\n",
      "mozc-2.29.5268.102/src/data/single_kanji//variant_rule.txt\n"
     ]
    }
   ],
   "source": [
    "# 異体字辞書を作成する \n",
    "!python extract_variant.py --indir=\"mozc-2.29.5268.102/src/data/single_kanji/\" --outfile=\"itaiji.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# 不要ファイルを削除する\n",
    "!rm -rf mozc-2.29.5268.102\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neologd\n",
    "ipadicからは，単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/neologd\n"
     ]
    }
   ],
   "source": [
    "%cd neologd\n",
    "!wget -nc -q https://github.com/neologd/mecab-ipadic-neologd/archive/refs/tags/v0.0.7.tar.gz --no-check-certificate\n",
    "!tar zxf v0.0.7.tar.gz\n",
    "!xz --decompress  mecab-ipadic-neologd-0.0.7/seed/*xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"indir\": \"mecab-ipadic-neologd-0.0.7/seed\",\n",
      "  \"outfile\": \"dict.txt\"\n",
      "}\n",
      "mecab-ipadic-neologd-0.0.7/seed/mecab-user-dict-seed.20200820.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-adjective-exp-dict-seed.20151126.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-adjective-std-dict-seed.20151126.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-adjective-verb-dict-seed.20160324.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-adverb-dict-seed.20150623.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-common-noun-ortho-variant-dict-seed.20170228.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-date-time-infreq-dict-seed.20190415.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-ill-formed-words-dict-seed.20170127.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-interjection-dict-seed.20170216.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-proper-noun-ortho-variant-dict-seed.20161110.csv\n",
      "mecab-ipadic-neologd-0.0.7/seed/neologd-quantity-infreq-dict-seed.20190415.csv\n"
     ]
    }
   ],
   "source": [
    "# 単語辞書を作成する，漢字とカタカナのペアのCSV形式\n",
    "!python extract_neologd.py --indir=\"mecab-ipadic-neologd-0.0.7/seed\" --outfile=\"dict.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"dict.txt\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する。単語辞書から一文字の漢字を抜き出す\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# 不要ファイルを削除する\n",
    "\n",
    "!rm -rf mecab-ipadic-neologd-0.0.7\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skk\n",
    "単語辞書と単漢字辞書を作成する。単漢字辞書は単語辞書から一文字の漢字を抜き出したもの。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/skk\n"
     ]
    }
   ],
   "source": [
    "%cd skk\n",
    "!wget -nc -q \"https://github.com/skk-dev/dict/raw/master/SKK-JISYO.jinmei\" --no-check-certificate\n",
    "!nkf -w --overwrite SKK-JISYO.jinmei\n",
    "\n",
    "!wget -nc -q \"https://github.com/skk-dev/dict/raw/master/SKK-JISYO.fullname\" --no-check-certificate\n",
    "!nkf -w --overwrite SKK-JISYO.fullname\n",
    "\n",
    "!wget -nc -q https://github.com/skk-dev/dict/raw/master/SKK-JISYO.itaiji --no-check-certificate\n",
    "!nkf -w --overwrite SKK-JISYO.itaiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"SKK-JISYO.jinmei\",\n",
      "  \"outfile\": \"skk_jinmei.txt\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"SKK-JISYO.fullname\",\n",
      "  \"outfile\": \"skk_fullname.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 姓名辞書を作成する\n",
    "!python jinmei.py --infile SKK-JISYO.jinmei --outfile skk_jinmei.txt\n",
    "!python fullname.py --infile SKK-JISYO.fullname --outfile skk_fullname.txt\n",
    "!cat skk_jinmei.txt skk_fullname.txt > dict.txt\n",
    "!rm -rf skk_jinmei.txt skk_fullname.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"dict.txt\",\n",
      "  \"outfile\": \"tankanji.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 単漢字辞書を作成する\n",
    "!python ../tankan.py --infile dict.txt --outfile tankanji.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"SKK-JISYO.itaiji\",\n",
      "  \"outfile\": \"itaiji.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 異体字辞書を作成する\n",
    "!python itaiji_skk.py --infile SKK-JISYO.itaiji  --outfile itaiji.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# 不要ファイルを削除する\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikipedia\n",
    "wikipediaからは，概要部分を抜き出して，文頭に　「漢字（読み）・・」　と記載されている場合に，漢字と読み仮名のペアを抜き出す。多少間違えている可能性があるので注意。\n",
    "\n",
    "\n",
    "Wikipediaの構造解析から，Abstract部分に着目する\n",
    "\n",
    "'''アルマ・マリア・マーラー＝ヴェルフェル'''（'''Alma Maria Mahler-Werfel''', [[1879年]][[8月31日]] – [[1964年]][[12月11日]]）は、[[オーストリア]]の作曲家[[グス\n",
    "タフ・マーラー]]の妻。結婚前の姓はシンドラー（Schindler）。自身も作曲を行い、16>の歌曲が今日に残されている。華麗な男性遍歴で知られる。 \n",
    "\n",
    "\n",
    "こんな形で入っている行をまずは抜き出す。     \n",
    "- 見出しの最初に，'''人名'''\n",
    "- ()の中に'''読み'''が入っている\n",
    "- ()の中に[[yyyy年]]\n",
    "- ()の中に[[mm月dd日]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/wikipedia\n"
     ]
    }
   ],
   "source": [
    "%cd wikipedia\n",
    "!wget -nc -q https://dumps.wikimedia.org/jawiki/latest/jawiki-latest-pages-articles.xml.bz2 --no-check-certificate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"jawiki-latest-pages-articles.xml.bz2\",\n",
      "  \"outfile\": \"abstract.txt\"\n",
      "}\n",
      "i=0\n",
      "i=1000000\n",
      "i=2000000\n",
      "i=3000000\n",
      "i=4000000\n",
      "i=5000000\n",
      "i=6000000\n",
      "i=7000000\n",
      "i=8000000\n",
      "i=9000000\n",
      "i=10000000\n",
      "i=11000000\n",
      "i=12000000\n",
      "i=13000000\n",
      "i=14000000\n",
      "i=15000000\n",
      "i=16000000\n",
      "i=17000000\n",
      "i=18000000\n",
      "i=19000000\n",
      "i=20000000\n",
      "i=21000000\n",
      "i=22000000\n",
      "i=23000000\n",
      "i=24000000\n",
      "i=25000000\n",
      "i=26000000\n",
      "i=27000000\n",
      "i=28000000\n",
      "i=29000000\n",
      "i=30000000\n",
      "i=31000000\n",
      "i=32000000\n",
      "i=33000000\n",
      "i=34000000\n",
      "i=35000000\n",
      "i=36000000\n",
      "i=37000000\n",
      "i=38000000\n",
      "i=39000000\n",
      "i=40000000\n",
      "i=41000000\n",
      "i=42000000\n",
      "i=43000000\n",
      "i=44000000\n",
      "i=45000000\n",
      "i=46000000\n",
      "i=47000000\n",
      "i=48000000\n",
      "i=49000000\n",
      "i=50000000\n",
      "i=51000000\n",
      "i=52000000\n",
      "i=53000000\n",
      "i=54000000\n",
      "i=55000000\n",
      "i=56000000\n",
      "i=57000000\n",
      "i=58000000\n",
      "i=59000000\n",
      "i=60000000\n",
      "i=61000000\n",
      "i=62000000\n",
      "i=63000000\n",
      "i=64000000\n",
      "i=65000000\n",
      "i=66000000\n",
      "i=67000000\n",
      "i=68000000\n",
      "i=69000000\n",
      "i=70000000\n",
      "i=71000000\n",
      "i=72000000\n",
      "i=73000000\n",
      "i=74000000\n",
      "i=75000000\n",
      "i=76000000\n",
      "i=77000000\n",
      "i=78000000\n",
      "i=79000000\n",
      "i=80000000\n",
      "i=81000000\n",
      "i=82000000\n",
      "i=83000000\n",
      "i=84000000\n",
      "i=85000000\n",
      "i=86000000\n",
      "i=87000000\n",
      "i=88000000\n",
      "i=89000000\n",
      "i=90000000\n",
      "i=91000000\n",
      "i=92000000\n",
      "i=93000000\n",
      "i=94000000\n",
      "i=95000000\n",
      "i=96000000\n",
      "i=97000000\n",
      "i=98000000\n",
      "i=99000000\n",
      "i=100000000\n",
      "i=101000000\n",
      "i=102000000\n",
      "i=103000000\n",
      "i=104000000\n",
      "i=105000000\n",
      "i=106000000\n",
      "i=107000000\n",
      "i=108000000\n",
      "i=109000000\n",
      "i=110000000\n",
      "i=111000000\n",
      "i=112000000\n",
      "i=113000000\n",
      "i=114000000\n",
      "i=115000000\n",
      "i=116000000\n",
      "i=117000000\n",
      "i=118000000\n",
      "i=119000000\n",
      "i=120000000\n",
      "i=121000000\n",
      "i=122000000\n",
      "i=123000000\n",
      "i=124000000\n",
      "i=125000000\n",
      "i=126000000\n",
      "i=127000000\n",
      "i=128000000\n",
      "i=129000000\n",
      "i=130000000\n",
      "i=131000000\n",
      "i=132000000\n",
      "i=133000000\n",
      "i=134000000\n",
      "i=135000000\n",
      "i=136000000\n",
      "i=137000000\n",
      "i=138000000\n",
      "i=139000000\n",
      "i=140000000\n",
      "i=141000000\n",
      "i=142000000\n",
      "i=143000000\n",
      "i=144000000\n",
      "i=145000000\n",
      "i=146000000\n",
      "i=147000000\n",
      "i=148000000\n",
      "i=149000000\n",
      "i=150000000\n",
      "i=151000000\n",
      "i=152000000\n",
      "i=153000000\n",
      "i=154000000\n",
      "i=155000000\n",
      "i=156000000\n",
      "i=157000000\n",
      "i=158000000\n",
      "i=159000000\n",
      "i=160000000\n",
      "i=161000000\n",
      "i=162000000\n",
      "i=163000000\n",
      "i=164000000\n",
      "i=165000000\n",
      "i=166000000\n",
      "i=167000000\n",
      "i=168000000\n",
      "i=169000000\n",
      "i=170000000\n",
      "i=171000000\n",
      "i=172000000\n",
      "i=173000000\n",
      "i=174000000\n",
      "i=175000000\n",
      "i=176000000\n",
      "i=177000000\n",
      "i=178000000\n",
      "i=179000000\n",
      "i=180000000\n",
      "i=181000000\n",
      "i=182000000\n",
      "i=183000000\n",
      "i=184000000\n",
      "i=185000000\n",
      "i=186000000\n",
      "i=187000000\n",
      "i=188000000\n",
      "i=189000000\n",
      "i=190000000\n",
      "i=191000000\n",
      "i=192000000\n",
      "i=193000000\n",
      "i=194000000\n",
      "i=195000000\n",
      "i=196000000\n",
      "i=197000000\n",
      "i=198000000\n",
      "i=199000000\n",
      "i=200000000\n",
      "i=201000000\n",
      "i=202000000\n",
      "i=203000000\n",
      "i=204000000\n",
      "i=205000000\n",
      "i=206000000\n",
      "i=207000000\n",
      "i=208000000\n",
      "i=209000000\n",
      "i=210000000\n",
      "i=211000000\n",
      "i=212000000\n",
      "i=213000000\n",
      "i=214000000\n",
      "i=215000000\n",
      "i=216000000\n",
      "i=217000000\n",
      "i=218000000\n",
      "i=219000000\n",
      "i=220000000\n",
      "i=221000000\n",
      "i=222000000\n",
      "i=223000000\n",
      "i=224000000\n",
      "i=225000000\n",
      "i=226000000\n",
      "i=227000000\n",
      "i=228000000\n",
      "i=229000000\n",
      "i=230000000\n",
      "i=231000000\n",
      "i=232000000\n",
      "i=233000000\n",
      "i=234000000\n",
      "i=235000000\n",
      "i=236000000\n",
      "i=237000000\n",
      "i=238000000\n",
      "i=239000000\n",
      "i=240000000\n",
      "i=241000000\n",
      "i=242000000\n",
      "i=243000000\n",
      "i=244000000\n",
      "i=245000000\n",
      "i=246000000\n",
      "i=247000000\n",
      "i=248000000\n"
     ]
    }
   ],
   "source": [
    "# Wikipediaから概要だけを抜き出す\n",
    "!python extract_wiki.py --infile=\"jawiki-latest-pages-articles.xml.bz2\" --outfile=\"abstract.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"outfile\": \"abstract_name.txt\",\n",
      "  \"infile\": \"abstract.txt\"\n",
      "}\n",
      "i=0\n",
      "i=10000\n",
      "i=20000\n",
      "i=30000\n",
      "i=40000\n",
      "i=50000\n",
      "i=60000\n",
      "i=70000\n",
      "i=80000\n",
      "i=90000\n",
      "i=100000\n",
      "i=110000\n",
      "i=120000\n",
      "i=130000\n",
      "i=140000\n",
      "i=150000\n",
      "i=160000\n",
      "i=170000\n",
      "i=180000\n",
      "i=190000\n",
      "i=200000\n",
      "i=210000\n",
      "i=220000\n",
      "i=230000\n",
      "{\n",
      "  \"infile\": \"abstract_name.txt\",\n",
      "  \"outfile\": \"wikiname.txt\",\n",
      "  \"ngfile\": \"ng.txt\"\n",
      "}\n",
      "i=0\n",
      "i=10000\n",
      "i=20000\n",
      "i=30000\n",
      "i=40000\n",
      "i=50000\n",
      "i=60000\n",
      "i=70000\n",
      "i=80000\n",
      "i=90000\n",
      "i=100000\n",
      "i=110000\n",
      "i=120000\n",
      "i=130000\n",
      "i=140000\n",
      "i=150000\n",
      "i=160000\n",
      "i=170000\n",
      "i=180000\n",
      "i=190000\n",
      "i=200000\n",
      "{\n",
      "  \"infile\": \"wikiname.txt\",\n",
      "  \"outfile\": \"dict.txt\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 漢字とカナのペアとなるものと推測されるものを抜き出す。\n",
    "!python extract_name.py --outfile=\"abstract_name.txt\" --infile=\"abstract.txt\";\n",
    "!python select_name.py --infile abstract_name.txt --outfile wikiname.txt --ngfile ng.txt;\n",
    "!python dict_name.py --infile wikiname.txt --outfile dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "# 不要ファイル削除\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ダウンロードしたデータから辞書を作成する\n",
    "\n",
    "## オープンソース辞書データ\n",
    "オープンソースの辞書から抜き出したデータで，oss.json,tankanji.json, itaiji.jsonを作成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "%cd dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"canna/dict.txt\",\n",
      "  \"jsonfile\": \"oss.json\",\n",
      "  \"dicname\": \"canna\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"freewnn/dict.txt\",\n",
      "  \"jsonfile\": \"oss.json\",\n",
      "  \"dicname\": \"freewnn\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"ipadic/dict.txt\",\n",
      "  \"jsonfile\": \"oss.json\",\n",
      "  \"dicname\": \"ipadic\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"kakasi/dict.txt\",\n",
      "  \"jsonfile\": \"oss.json\",\n",
      "  \"dicname\": \"kakasi\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"mozc/dict.txt\",\n",
      "  \"jsonfile\": \"oss.json\",\n",
      "  \"dicname\": \"mozc\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"neologd/dict.txt\",\n",
      "  \"jsonfile\": \"oss.json\",\n",
      "  \"dicname\": \"neologd\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"skk/dict.txt\",\n",
      "  \"jsonfile\": \"oss.json\",\n",
      "  \"dicname\": \"skk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# oss.json\n",
    "!rm -rf oss.json\n",
    "!python merge.py --infile canna/dict.txt --jsonfile oss.json --dicname canna;\n",
    "!python merge.py --infile freewnn/dict.txt --jsonfile oss.json --dicname freewnn;\n",
    "!python merge.py --infile ipadic/dict.txt --jsonfile oss.json --dicname ipadic;\n",
    "!python merge.py --infile kakasi/dict.txt --jsonfile oss.json --dicname kakasi;\n",
    "!python merge.py --infile mozc/dict.txt --jsonfile oss.json --dicname mozc;\n",
    "!python merge.py --infile neologd/dict.txt --jsonfile oss.json --dicname neologd;\n",
    "!python merge.py --infile skk/dict.txt --jsonfile oss.json --dicname skk;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"canna/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"canna\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"freewnn/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"freewnn\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"ipadic/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"ipadic\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"kakasi/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"kakasi\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"mozc/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"mozc\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"neologd/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"neologd\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"skk/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"skk\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"mj/tankanji.txt\",\n",
      "  \"jsonfile\": \"tankanji.json\",\n",
      "  \"dicname\": \"mj\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# tankanji.json\n",
    "!rm -rf tankanji.json\n",
    "\n",
    "!python merge.py --infile canna/tankanji.txt --jsonfile tankanji.json --dicname canna;\n",
    "!python merge.py --infile freewnn/tankanji.txt --jsonfile tankanji.json --dicname freewnn;\n",
    "!python merge.py --infile ipadic/tankanji.txt --jsonfile tankanji.json --dicname ipadic;\n",
    "!python merge.py --infile kakasi/tankanji.txt --jsonfile tankanji.json --dicname kakasi;\n",
    "!python merge.py --infile mozc/tankanji.txt --jsonfile tankanji.json --dicname mozc;\n",
    "!python merge.py --infile neologd/tankanji.txt --jsonfile tankanji.json --dicname neologd;\n",
    "!python merge.py --infile skk/tankanji.txt --jsonfile tankanji.json --dicname skk;\n",
    "!python merge.py --infile mj/tankanji.txt --jsonfile tankanji.json --dicname mj;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"kakasi/itaiji.txt\",\n",
      "  \"jsonfile\": \"itaiji.json\",\n",
      "  \"dicname\": \"kakasi\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"mozc/itaiji.txt\",\n",
      "  \"jsonfile\": \"itaiji.json\",\n",
      "  \"dicname\": \"mozc\"\n",
      "}\n",
      "{\n",
      "  \"infile\": \"skk/itaiji.txt\",\n",
      "  \"jsonfile\": \"itaiji.json\",\n",
      "  \"dicname\": \"skk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# itaiji.json\n",
    "!rm -rf itaiji.json\n",
    "!python merge.py --infile kakasi/itaiji.txt --jsonfile itaiji.json --dicname kakasi\n",
    "!python merge.py --infile mozc/itaiji.txt --jsonfile itaiji.json --dicname mozc\n",
    "!python merge.py --infile skk/itaiji.txt --jsonfile itaiji.json --dicname skk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webデータ\n",
    "wikipediaから抜き出したデータから，姓名の漢字とカナのペアで，seimei.jsonを作成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/analysis01/src/kanjikana-model/dict/wikipedia\n",
      "{\n",
      "  \"infile\": \"dict.txt\",\n",
      "  \"outfile\": \"dict_add.txt\",\n",
      "  \"oss\": \"../oss.json\"\n",
      "}\n",
      "total=113099,cnt=41879\n",
      "/home/analysis01/src/kanjikana-model/dict\n"
     ]
    }
   ],
   "source": [
    "%cd wikipedia\n",
    "# オープンソースの辞書のデータに入っていない漢字とカナのペアを抜き出す\n",
    "!python check_dict.py --infile dict.txt --outfile dict_add.txt --oss ../oss.json;\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"infile\": \"wikipedia/dict.txt\",\n",
      "  \"jsonfile\": \"seimei.json\",\n",
      "  \"dicname\": \"wikipedia\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!rm -rf seimei.json\n",
    "!python merge.py --infile wikipedia/dict.txt --jsonfile seimei.json --dicname wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他\n",
    "その他，氏名漢字カナ突合モデルに必要な空ファイルを作成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"crawl.json\",'w',encoding='utf-8') as f:\n",
    "    f.write(\"{}\")\n",
    "\n",
    "with open(\"statistics.json\",'w',encoding='utf-8') as f:\n",
    "    f.write(\"{}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
